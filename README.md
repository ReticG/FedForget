# FedForget: Federated Unlearning via Dual-Teacher Knowledge Distillation

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch 1.10+](https://img.shields.io/badge/PyTorch-1.10+-orange.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)

> **Official implementation of "FedForget: Federated Unlearning via Dual-Teacher Knowledge Distillation"**
>
> Submitted to ICML 2025 / NeurIPS 2025

---

## ğŸ“– Overview

**FedForget** is a novel federated unlearning framework that enables efficient and effective data deletion in federated learning systems while preserving model utility. Our key innovation is **dual-teacher knowledge distillation**, which addresses the fundamental limitation of existing single-teacher approachesâ€”teacher contamination.

### Key Features

- ğŸ¯ **Dual-Teacher Knowledge Distillation**: Combines global teacher (preserving overall structure) and local teacher (providing clean reference)
- âš¡ **Dynamic Weight Adjustment**: Server-side exponential weight decay for smooth unlearning
- ğŸ”’ **Strong Privacy Guarantee**: ASRâ‰ˆ50% (near-ideal privacy protection)
- ğŸ“ˆ **Superior Scalability**: Performance improves with more clients (+2.09% retention for 10 vs 5 clients)
- ğŸš€ **High Efficiency**: 1.53-1.75Ã— speedup over complete retraining

### Main Results (CIFAR-10, 5 clients)

| Method | Test Acc | Retention | Forgetting | ASR | Speedup |
|--------|----------|-----------|------------|-----|---------|
| Retrain | 67.92Â±1.58 | 93.96Â±2.33 | **32.68Â±1.49** | 46.74Â±2.26 | 1Ã— |
| FineTune | **70.99Â±0.95** | **98.22Â±1.79** | 15.70Â±1.90 | 51.14Â±2.42 | 2.02Ã— |
| **FedForget** | 69.81Â±1.51 | 96.57Â±1.21 | 20.01Â±1.92 | **52.91Â±2.32** | **1.53Ã—** |

*Averaged over 3 independent runs (seeds: 42, 123, 456)*

---

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/YOUR_USERNAME/fedforget.git
cd fedforget

# Create virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Basic Usage

```python
from unlearn import FedForgetUnlearner

# Initialize unlearner
unlearner = FedForgetUnlearner(
    num_clients=5,
    alpha=0.95,          # Knowledge distillation weight
    lambda_neg=3.0,      # Negative learning strength
    lambda_forget=1.5    # Server weight decay factor
)

# Run federated unlearning
results = unlearner.unlearn(
    forget_clients=[0],  # Client(s) to forget
    num_rounds=10        # Unlearning rounds
)

print(f"Retention: {results['retention']:.2f}%")
print(f"Forgetting: {results['forgetting']:.2f}%")
print(f"ASR: {results['asr']:.2f}%")
```

### Reproducing Paper Results

```bash
# Main experiments (5 clients, 3 seeds)
python scripts/compare_all_methods.py --num_clients 5 --alpha 0.5 --seeds 42 123 456

# Ablation study
python scripts/test_ablation.py --alpha 0.5 --seed 42

# Scalability evaluation (10 clients)
python scripts/compare_10clients.py --alpha 0.5 --seeds 42 123 456

# Generate figures
python scripts/generate_paper_figures.py
```

---

## ğŸ“Š Experimental Results

### 1. Main Results (5 Clients)

FedForget achieves the best multi-objective balance:

- âœ… **Effectiveness**: 20.01Â±1.92% forgetting rate (effective unlearning)
- âœ… **Utility**: 96.57Â±1.21% retention (minimal performance loss)
- âœ… **Privacy**: ASR=52.91Â±2.32% (closest to ideal 50%, best among all methods)
- âœ… **Efficiency**: 1.53Ã— speedup over complete retraining
- âœ… **Stability**: Lowest variance across 3 runs (Retention CV=1.25%)

### 2. Ablation Study

| Variant | Test Acc | Retention | Forgetting | Impact |
|---------|----------|-----------|------------|--------|
| **Full FedForget** | **71.85** | **101.07** | **11.38** | Baseline |
| No Weight Adj. | 71.38 | 100.86 | 14.43 | â­ Minor (-0.21%) |
| **No Distillation** | 10.00 | 14.10 | 93.66 | â­â­â­â­â­ Critical (-87%) |
| Single Teacher | 63.96 | 89.53 | 29.90 | â­â­â­â­ Major (-11.54%) |

**Key Finding**: Dual-teacher mechanism contributes **+11.54% retention** vs single-teacher, validating our core innovation.

### 3. Scalability (5 vs 10 Clients)

**Counter-intuitive Discovery**: FedForget performs *better* with more clients!

| Metric | 5 Clients | 10 Clients | Change |
|--------|-----------|------------|--------|
| Test Acc | 69.81Â±1.51 | 68.93Â±0.52 | -0.88% (stable) |
| **Retention** | 96.57Â±1.21 | **98.66Â±1.37** | **+2.09%** âœ… |
| **ASR** | 52.91Â±2.32 | **50.23Â±1.62** | **-2.68%** âœ… (closer to 50%) |
| Stability (CV) | 2.16% | **0.75%** | -65% variance |

**Why?** More clients lead to dilution effect, knowledge richness, and fine-grained weight adjustment.

---

## ğŸ—ï¸ Architecture

### Dual-Teacher Knowledge Distillation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            FedForget Architecture            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                              â”‚
â”‚  Client-Side: Dual-Teacher Distillation      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚Teacher A â”‚              â”‚Teacher B â”‚     â”‚
â”‚  â”‚ (Global) â”‚              â”‚ (Local)  â”‚     â”‚
â”‚  â”‚  Î¸_A     â”‚              â”‚   Î¸_B    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜     â”‚
â”‚       â”‚     KL Divergence       â”‚            â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚               â†“                              â”‚
â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚       â”‚   Student Î¸   â”‚                      â”‚
â”‚       â”‚  (Unlearning) â”‚                      â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚               â”‚                              â”‚
â”‚               â†“  Negative Learning           â”‚
â”‚       Loss = Î±Â·L_KD + (1-Î±)Â·L_forget        â”‚
â”‚                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Server-Side: Dynamic Weight Adjustment      â”‚
â”‚                                              â”‚
â”‚       w_i^(t) = w_i^(t-1) / Î»_forget        â”‚
â”‚       (for forgetting clients)               â”‚
â”‚                                              â”‚
â”‚       Î¸^(t) = Î£ w_i^(t) Â· Î¸_i^(t)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Algorithm Overview

1. **Teacher A Construction**: Use pre-trained global model
2. **Teacher B Construction**: Train on remaining clients' data only
3. **Client Unlearning**: Dual-teacher distillation + negative learning
4. **Server Aggregation**: Dynamic weight decay for forgetting clients
5. **Iterate**: Repeat for T_unlearn rounds (typically 10)

---

## ğŸ“ Project Structure

```
fedforget/
â”œâ”€â”€ unlearn.py                      # Core FedForget implementation
â”œâ”€â”€ models.py                       # Neural network models (ResNet-18)
â”œâ”€â”€ dataset.py                      # Data loading & Non-IID partitioning
â”œâ”€â”€ mia.py                          # Membership Inference Attack evaluation
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ compare_all_methods.py     # Main experiments (Retrain/FineTune/FedForget)
â”‚   â”œâ”€â”€ test_ablation.py           # Ablation study (4 variants)
â”‚   â”œâ”€â”€ compare_10clients.py       # Scalability evaluation
â”‚   â”œâ”€â”€ generate_paper_figures.py  # Auto-generate all figures
â”‚   â”œâ”€â”€ check_consistency.py       # Terminology consistency check
â”‚   â””â”€â”€ fix_terminology.py         # Automated term fixing
â”œâ”€â”€ figures/                        # Generated figures (PNG + PDF)
â”‚   â”œâ”€â”€ figure1_main_results.pdf   # Main results comparison
â”‚   â”œâ”€â”€ figure2_ablation_study.pdf # Ablation study
â”‚   â”œâ”€â”€ figure3_scalability.pdf    # Scalability analysis
â”‚   â””â”€â”€ figure4_dynamic_weights.pdf # Weight decay visualization
â”œâ”€â”€ results/                        # Experimental results (CSV)
â”‚   â”œâ”€â”€ reproducibility_stats.csv  # Main results (3 seeds)
â”‚   â”œâ”€â”€ ablation_study.csv         # Ablation results
â”‚   â”œâ”€â”€ compare_10clients_stats.csv # Scalability results
â”‚   â””â”€â”€ ...
â”œâ”€â”€ logs/                           # Training & unlearning logs
â”œâ”€â”€ paper_main.tex                  # LaTeX main file
â”œâ”€â”€ references.bib                  # BibTeX bibliography (35 entries)
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ README.md                       # This file
â””â”€â”€ LICENSE                         # MIT License
```

---

## ğŸ”§ Configuration

### Hyperparameters

| Parameter | Description | Default | Recommended Range |
|-----------|-------------|---------|-------------------|
| `alpha` | KD weight (distillation vs forgetting) | 0.95 | 0.93-0.97 |
| `beta` | Teacher balance (A vs B) | 0.5 | 0.4-0.6 |
| `lambda_neg` | Negative learning strength | 3.0 | 2.0-3.5 |
| `lambda_forget` | Server weight decay factor | 1.5 | 1.3-2.0 |
| `T_unlearn` | Number of unlearning rounds | 10 | 10-15 |

### Pre-configured Modes

**Conservative** (prioritize utility):
```python
FedForgetUnlearner(alpha=0.97, lambda_neg=1.5, lambda_forget=1.5)
# Result: ~12% forgetting, ~100% retention
```

**Standard** (balanced, **recommended**):
```python
FedForgetUnlearner(alpha=0.95, lambda_neg=3.0, lambda_forget=1.5)
# Result: ~20% forgetting, ~97% retention
```

**Aggressive** (prioritize unlearning):
```python
FedForgetUnlearner(alpha=0.93, lambda_neg=3.5, lambda_forget=2.0)
# Result: ~40% forgetting, ~89% retention
```

---

## ğŸ“ˆ Performance Metrics

### Evaluation Metrics

1. **Test Accuracy**: Model accuracy on global test set
2. **Retention**: `(Test Acc after / Test Acc pretrain) Ã— 100%` â†‘ higher is better
3. **Forgetting Rate**: `(1 - Forget Acc after / Forget Acc pretrain) Ã— 100%` â†‘ higher is better
4. **Attack Success Rate (ASR)**: SimpleMIA success rate â†’ ideal â‰ˆ 50%
5. **Computational Time**: Wall-clock time â†“ lower is better

### Privacy Evaluation via SimpleMIA

We use loss-based membership inference attack to evaluate privacy:
- **ASR â‰ˆ 50%**: Ideal privacy (random guessing)
- **ASR > 50%**: Potential privacy leakage
- **ASR < 50%**: Over-generalization

**FedForget achieves**: 52.91Â±2.32% (5 clients), **50.23Â±1.62% (10 clients)** â† closest to ideal!

---

## ğŸ§ª Running Experiments

### Complete Reproducibility

```bash
# Run all main experiments (takes ~2 hours on RTX 4090)
./run_all_experiments.sh

# Or run individually:

# 1. Main experiments (5 clients, 3 seeds)
python scripts/compare_all_methods.py \
    --num_clients 5 \
    --alpha 0.5 \
    --seeds 42 123 456 \
    --output results/reproducibility.csv

# 2. Ablation study
python scripts/test_ablation.py \
    --alpha 0.5 \
    --seed 42 \
    --output results/ablation_study.csv

# 3. Scalability (10 clients)
python scripts/compare_10clients.py \
    --alpha 0.5 \
    --seeds 42 123 456 \
    --output results/compare_10clients.csv

# 4. Generate all figures (300 DPI PNG + PDF)
python scripts/generate_paper_figures.py
```

### Custom Experiments

```bash
# Different Non-IID levels
python scripts/compare_all_methods.py --alpha 0.1  # Extreme Non-IID
python scripts/compare_all_methods.py --alpha 1.0  # Near-IID

# Different client numbers
python scripts/compare_all_methods.py --num_clients 10
python scripts/compare_all_methods.py --num_clients 20

# Parameter search
python scripts/parameter_search.py \
    --alpha_range 0.93 0.95 0.97 \
    --lambda_neg_range 2.0 3.0 3.5
```

---

## ğŸ“ Citation

If you find FedForget useful in your research, please cite our paper:

```bibtex
@inproceedings{fedforget2025,
  title={FedForget: Federated Unlearning via Dual-Teacher Knowledge Distillation},
  author={Anonymous},
  booktitle={Proceedings of the International Conference on Machine Learning (ICML)},
  year={2025},
  note={Under review}
}
```

---

## ğŸ“„ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

We thank the reviewers for their valuable feedback. This work builds upon:
- **FedAvg** (McMahan et al., AISTATS 2017)
- **FedEraser** (Liu et al., NeurIPS 2021)
- **KNOT** (Wu et al., ICLR 2023)
- **Ferrari** (Ferrari et al., NeurIPS 2024)

---

## ğŸ“§ Contact

For questions, please:
- Open an [Issue](https://github.com/YOUR_USERNAME/fedforget/issues)
- Email: anonymous@institution.edu (will be updated upon acceptance)

---

## ğŸ“š Related Papers

### Federated Unlearning
- [FedEraser](https://arxiv.org/abs/2103.03228) (NeurIPS 2021)
- [KNOT](https://arxiv.org/abs/2211.10259) (ICLR 2023)
- [Ferrari](https://arxiv.org/abs/2403.08541) (NeurIPS 2024)

### Machine Unlearning
- [SISA](https://arxiv.org/abs/1912.03817) (IEEE S&P 2021)
- [Influence Functions](https://arxiv.org/abs/1703.04730) (ICML 2017)

### Knowledge Distillation
- [Hinton et al.](https://arxiv.org/abs/1503.02531) (NIPS 2014 Workshop)

---

<div align="center">

**Project Status**: ğŸ‰ **Experiments Complete** | ğŸ“ **Paper Under Review**

**Last Updated**: 2025-10-06 | **Version**: 1.0.0

â­ **Star this repo if you find it useful!** â­

</div>
