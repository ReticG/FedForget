# FedForget 实验设置说明

## 📋 实验目标

**核心问题**: 如何在联邦学习中让模型"遗忘"特定客户端的数据贡献？

**应用场景**:
- 用户行使"被遗忘权"（GDPR等隐私法规）
- 客户端退出联邦学习系统
- 移除恶意/低质量客户端的影响

**评估标准**:
1. **模型效用保持**: 在测试集上的准确率保持>85-90%
2. **遗忘效果**: 在遗忘客户端数据上的准确率显著下降(>10-30%)
3. **效率**: 比从头重新训练(Retrain)更快

---

## 🎯 实验思路

### 核心思想

我们模拟一个**联邦学习场景**，其中：

1. **预训练阶段**:
   - 多个客户端（5个）共同训练一个全局模型
   - 使用FedAvg聚合算法
   - 训练完成后，模型在所有客户端的数据上表现良好

2. **遗忘需求**:
   - 客户端0要求被遗忘
   - 需要从已训练的全局模型中移除客户端0的数据影响

3. **遗忘实现**:
   - 对比多种遗忘方法的效果
   - 在保持模型性能的同时，降低在客户端0数据上的准确率

---

## 🔧 实验设置

### 1. 数据设置

**数据集**: CIFAR-10 (当前最佳选择)
```
- 50,000训练图像, 10,000测试图像
- 10个类别: 飞机、汽车、鸟、猫、鹿、狗、青蛙、马、船、卡车
- 32x32彩色图像 (3通道)
```

**为什么选CIFAR-10**:
- ✅ MNIST太简单，泛化性太强，遗忘效果差(<2%)
- ✅ CIFAR-10复杂度适中，遗忘效果显著(~30%)
- ✅ 标准benchmark，论文中常用

**数据分布**: Non-IID (Dirichlet alpha=0.5)
```python
fed_data = load_federated_data(
    dataset_name='cifar10',
    num_clients=5,
    data_dist='noniid',
    dirichlet_alpha=0.5,
    data_root='/home/featurize/data'
)
```

**Dirichlet分布原理**:
- alpha越小 → 数据分布越不平衡（更Non-IID）
- alpha=0.1: 极端不平衡，可能导致某些客户端缺少某些类别
- alpha=0.5: **平衡的Non-IID** ← 当前使用
- alpha=10: 接近IID

**数据分布示例** (客户端0):
```
客户端0 (10663样本):
  狗:    4099 (38.4%)  ← 占优势
  青蛙:  2715 (25.5%)  ← 占优势
  鸟:    1766 (16.6%)
  船:     866 ( 8.1%)
  飞机:   583 ( 5.5%)
  卡车:   627 ( 5.9%)
  汽车:     1 ( 0.0%)  ← 几乎没有
  猫:       5 ( 0.0%)
  鹿:       1 ( 0.0%)
  马:       0 ( 0.0%)  ← 完全没有
```

**关键特点**:
- 客户端0在"狗"、"青蛙"类别上有数据优势
- 客户端0在"汽车"、"猫"、"鹿"、"马"上几乎没有数据
- 这种异质性是遗忘有效的前提

### 2. 联邦学习设置

**模型架构**: ConvNet
```python
class ConvNet(nn.Module):
    # 2个卷积层 + 1个全连接层
    - Conv1: 3→32, 5x5 kernel
    - Conv2: 32→64, 5x5 kernel
    - FC: 64*5*5 → 512 → 10
```

**预训练配置**:
```python
num_clients = 5           # 客户端数量
pretrain_rounds = 20      # 联邦学习轮数
local_epochs = 2          # 每轮本地训练epoch数
batch_size = 64
learning_rate = 0.01      # CIFAR-10使用较小学习率
optimizer = SGD(momentum=0.9)
```

**FedAvg聚合**:
```python
# 按样本量加权聚合
w_global = Σ(n_i / N) * w_i

其中:
- w_i: 客户端i的模型参数
- n_i: 客户端i的样本数
- N: 所有客户端总样本数
```

**预训练结果** (CIFAR-10):
```
测试准确率: 70.91%
遗忘数据准确率: 84.44% (在客户端0数据上)
```

### 3. 遗忘方法对比

我们对比**4种方法**:

#### 方法1: No Unlearning (基线 - 最差)
```
什么都不做，保留原模型
- 测试准确率: 70.91%
- 遗忘数据准确率: 84.44%
- 遗忘率: 0%
```

#### 方法2: Retrain (理想基线 - 最好但最慢)
```
从头重新训练，完全排除客户端0

步骤:
1. 重新初始化模型
2. 只用客户端1-4的数据进行联邦训练(20轮)
3. 不包含客户端0

结果 (CIFAR-10):
- 测试准确率: 68.69% (保持率96.9%)
- 遗忘数据准确率: 56.82% (遗忘率32.7%)
- 耗时: 114.3s

优点: 完美遗忘（相当于从未训练过客户端0）
缺点: 耗时长，需要重新训练整个模型
```

#### 方法3: Fine-tuning (快速但遗忘不足)
```
在剩余数据上继续训练

步骤:
1. 加载预训练模型
2. 用客户端1-4的数据继续训练(10轮)
3. 使用较小学习率(0.005)

结果 (CIFAR-10):
- 测试准确率: 70.69% (保持率99.7%)
- 遗忘数据准确率: 68.73% (遗忘率18.6%)
- 耗时: 56.4s

优点: 速度快，性能保持好
缺点: 遗忘效果一般（只能稀释影响，不能主动遗忘）
```

#### 方法4: FedForget (我们的方法)
```
双教师知识蒸馏 + 动态权重调整

核心思想:
1. 遗忘客户端: 执行"负向学习"
   - 学习全局模型的知识（正向）
   - 遗忘自己数据的影响（负向）

2. 常规客户端: 继续正常训练

3. 服务器聚合: 给予遗忘客户端更高权重

步骤:
1. 保存预训练模型作为"教师A"（固定不变）
2. 遗忘客户端执行双教师知识蒸馏:
   loss = alpha * KL(student || 教师A) - (1-alpha) * lambda_neg * CE(student, labels)
3. 服务器聚合时提升遗忘客户端权重(lambda_forget倍)
4. 迭代10轮

参数:
- alpha = 0.95          # 95%正向学习, 5%负向遗忘
- lambda_neg = 3.0      # 负向遗忘强度
- lambda_forget = 1.5   # 服务器端权重提升
- distill_temp = 2.0    # 蒸馏温度
- unlearn_lr = 0.005    # 遗忘学习率

结果 (CIFAR-10):
- 测试准确率: 65.30% (保持率92.1%)
- 遗忘数据准确率: 62.53% (遗忘率25.9%)
- 耗时: 43.2s

优点:
- 遗忘效果接近Retrain (25.9% vs 32.7%)
- 速度快 (43.2s vs 114.3s)
缺点:
- 性能保持略低于Fine-tuning (92.1% vs 99.7%)
- 参数难以调优
```

---

## 📊 评估指标

### 主要指标

**1. 测试准确率 (Test Accuracy)**
```
在独立测试集(10,000样本)上的准确率
→ 衡量模型的整体性能保持
```

**2. 遗忘数据准确率 (Forget Accuracy)**
```
在客户端0的数据上的准确率
→ 衡量遗忘效果（越低越好）
```

**3. 保持率 (Retention Ratio)**
```
保持率 = (遗忘后测试准确率) / (预训练测试准确率)
→ 目标: >85-90%
```

**4. 遗忘率 (Forgetting Ratio)**
```
遗忘率 = (预训练遗忘准确率 - 遗忘后遗忘准确率) / 预训练遗忘准确率
→ 目标: >10-30%

示例: 84.44% → 56.82%
遗忘率 = (84.44 - 56.82) / 84.44 = 32.7%
```

**5. 各类别准确率**
```
分析每个类别的遗忘效果
→ 检验客户端数据优势类别是否被有效遗忘
```

### 成功标准

**CIFAR-10**:
- ✅ 保持率 > 85%
- ✅ 遗忘率 > 10%
- ✅ 比Retrain更快

**MNIST**:
- ⚠️ 遗忘率普遍<2%，不适合评估遗忘

---

## 🔬 实验发现

### 发现1: 数据集选择至关重要

**MNIST失败原因**:
```
问题: 即使Retrain遗忘率也只有1.6%

原因: MNIST泛化性太强
- 客户端0在类别8有5596个样本
- 其他客户端合计只有255个样本 (21.9倍差距!)
- 但排除客户端0后，准确率只下降0.79%
- 说明255个样本就足以学好数字"8"

结论: MNIST的10个手写数字太简单，少量样本即可泛化
```

**CIFAR-10成功原因**:
```
成功: Retrain遗忘率32.7%，FedForget遗忘率25.9%

原因: CIFAR-10复杂度适中
- 真实物体图像，包含纹理、颜色、形状等复杂特征
- 需要足够样本才能学好每个类别
- 客户端0数据优势的类别，遗忘后下降明显:
  * 狗: 71.02% → 33.84% (下降37.18%)
  * 鸟: 91.51% → 64.38% (下降27.12%)

结论: 复杂数据集更适合评估遗忘效果
```

### 发现2: 数据分布影响遗忘效果

**IID设置**:
```
问题: 所有客户端数据分布相同
- 客户端0的数据100%可被其他客户端替代
- 每个类别在其他客户端中有4倍样本量
结论: 完全无法遗忘
```

**Non-IID (alpha=0.1)**:
```
问题: 数据分布极度不平衡
- 某些客户端完全缺少某些类别
- Retrain基线崩溃 (测试准确率10.09%)
结论: 过于极端，基线无法正常训练
```

**Non-IID (alpha=0.5)** ✅:
```
成功: 平衡的Non-IID
- 客户端间有数据差异
- 但每个客户端都有足够数据训练
- Retrain正常工作
结论: 推荐使用
```

### 发现3: FedForget参数极难平衡

**alpha参数** (正向vs负向学习):
```
alpha < 0.5  → 模型崩溃 (9.8%准确率)
alpha = 0.7  → 需要测试
alpha = 0.85 → 需要测试
alpha = 0.90 → 模型崩溃 (MNIST上)
alpha = 0.95 → 遗忘25.9% (CIFAR-10上) ✅

核心矛盾:
- 需要强遗忘 → 降低alpha，增大负向学习
- 但负向过强 → 模型崩溃
```

**lambda_neg参数** (负向强度):
```
lambda_neg = 1.0  → 遗忘较弱
lambda_neg = 3.0  → 当前使用 ✅
lambda_neg = 5.0+ → 容易崩溃（配合低alpha）
```

**lambda_forget参数** (服务器权重):
```
lambda_forget = 1.0  → 权重提升小
lambda_forget = 1.5  → 当前使用 ✅
lambda_forget = 10.0 → 导致崩溃（MNIST上）
```

---

## 🚀 当前最佳配置

### CIFAR-10推荐配置

```python
# 数据
dataset_name = 'cifar10'
num_clients = 5
data_dist = 'noniid'
dirichlet_alpha = 0.5

# 预训练
pretrain_rounds = 20
local_epochs = 2
learning_rate = 0.01
batch_size = 64

# FedForget遗忘
unlearn_rounds = 10
unlearn_lr = 0.005
alpha = 0.95              # 待优化: 可尝试0.85-0.93
lambda_neg = 3.0          # 待优化: 可尝试5.0-8.0
lambda_forget = 1.5
distill_temp = 2.0
```

### 实验结果

| 方法 | 测试准确率 | 遗忘准确率 | 保持率 | 遗忘率 | 耗时 | 评价 |
|------|----------|----------|-------|-------|-----|------|
| No Unlearning | 70.91% | 84.44% | 100% | 0% | 0s | 基线 |
| Retrain | 68.69% | 56.82% | 96.9% | **32.7%** | 114.3s | 理想 |
| Fine-tuning | 70.69% | 68.73% | **99.7%** | 18.6% | 56.4s | 快速 |
| **FedForget** | 65.30% | 62.53% | 92.1% | **25.9%** | **43.2s** | **平衡** |

**结论**:
✅ FedForget在CIFAR-10上达到了预期效果
✅ 遗忘率25.9%，接近Retrain的32.7%
✅ 速度快于Retrain (43.2s vs 114.3s)
⚠️ 性能保持略低 (92.1% vs Fine-tuning的99.7%)

---

## 📝 下一步工作

### 高优先级

1. **FedForget参数优化** (CIFAR-10)
   - 系统搜索alpha: [0.85, 0.88, 0.90, 0.92, 0.95]
   - 测试lambda_neg: [3.0, 5.0, 8.0]
   - 目标: 提升遗忘率到>30%，同时保持率>90%

2. **实现MIA评估**
   - 成员推断攻击 (Membership Inference Attack)
   - ASR (Attack Success Rate)
   - 更全面的隐私评估

3. **类别遗忘实验**
   - 让遗忘客户端拥有某类别的全部数据
   - 测试是否能完全遗忘该类别

### 中优先级

4. **更多数据集**
   - CIFAR-100 (更细粒度)
   - Fashion-MNIST

5. **更多基线方法**
   - SCRUB
   - FedEraser
   - SISA

---

## 💡 核心洞察

1. **数据集复杂度是遗忘有效性的关键**
   - 简单数据集(MNIST): 泛化太强 → 遗忘无效
   - 复杂数据集(CIFAR-10): 需要足够数据 → 遗忘有效

2. **数据异质性是遗忘的前提**
   - IID: 数据完全重合 → 无法遗忘
   - Non-IID: 客户端有独特数据 → 可以遗忘

3. **FedForget参数平衡是核心挑战**
   - alpha太低 → 崩溃
   - alpha太高 → 遗忘不足
   - 需要针对不同数据集调优

4. **遗忘≠删除**
   - Retrain是理想基线（完全删除）
   - FedForget是近似遗忘（降低影响）
   - 权衡: 效果 vs 效率

---

**文档版本**: v2.0
**最后更新**: 2025-10-04 Day 2
**实验状态**: CIFAR-10验证成功 ✅
