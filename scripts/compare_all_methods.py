#!/usr/bin/env python3
"""
å®Œæ•´å¯¹æ¯”æ‰€æœ‰é—å¿˜æ–¹æ³•

å¯¹æ¯”:
1. Retrain - ä»å¤´é‡æ–°è®­ç»ƒ(ç†æƒ³åŸºçº¿)
2. Fine-tuning - åœ¨å‰©ä½™æ•°æ®ä¸Šç»§ç»­è®­ç»ƒ
3. FedForget - æˆ‘ä»¬çš„æ–¹æ³•
4. No unlearning - ä¸åšä»»ä½•å¤„ç†(æœ€å·®åŸºçº¿)

è¯„ä¼°æŒ‡æ ‡:
- Test Accuracy: æµ‹è¯•å‡†ç¡®ç‡(æ¨¡å‹æ•ˆç”¨)
- Forget Accuracy: é—å¿˜æ•°æ®å‡†ç¡®ç‡(é—å¿˜æ•ˆæœ)
- Retention Ratio: æµ‹è¯•å‡†ç¡®ç‡ä¿æŒç‡
- Forgetting Ratio: é—å¿˜æ•°æ®å‡†ç¡®ç‡ä¸‹é™ç‡
"""

import sys
sys.path.append('/home/featurize/work/GJC/fedforget')

import torch
import numpy as np
import time

from src.data import load_federated_data
from src.models import ConvNet
from src.federated import Client, Server
from src.federated.server import FedForgetServer
from src.federated.client import UnlearningClient
from src.unlearning.baselines import RetrainBaseline, FineTuningBaseline
from src.utils.metrics import evaluate_model

# å›ºå®šéšæœºç§å­
torch.manual_seed(42)
np.random.seed(42)
device = 'cuda' if torch.cuda.is_available() else 'cpu'

print("="*80)
print("æœºå™¨é—å¿˜æ–¹æ³•å®Œæ•´å¯¹æ¯”å®éªŒ")
print("="*80)

# ============================================================
# æ•°æ®å‡†å¤‡
# ============================================================
print("\n[1/5] æ•°æ®åŠ è½½...")
fed_data = load_federated_data(
    dataset_name='mnist',
    num_clients=5,
    data_dist='iid',
    data_root='/home/featurize/data'
)

test_loader = fed_data.get_test_loader(batch_size=256)
client0_loader = fed_data.get_client_loader(0, batch_size=64)  # é—å¿˜å®¢æˆ·ç«¯
retain_loaders = [fed_data.get_client_loader(i, batch_size=64) for i in [1, 2, 3, 4]]

print(f"âœ“ æ•°æ®åŠ è½½å®Œæˆ")
print(f"  æ€»å®¢æˆ·ç«¯æ•°: 5")
print(f"  é—å¿˜å®¢æˆ·ç«¯: 0")
print(f"  ä¿ç•™å®¢æˆ·ç«¯: 1, 2, 3, 4")

# ============================================================
# é¢„è®­ç»ƒ (æ‰€æœ‰æ–¹æ³•å…±ç”¨)
# ============================================================
print("\n[2/5] é¢„è®­ç»ƒæ¨¡å‹ (10è½®)...")
model = ConvNet(num_classes=10, num_channels=1)
server = Server(model=model, device=device)

clients = []
for i in range(5):
    client_loader = fed_data.get_client_loader(i, batch_size=64)
    client = Client(
        client_id=i,
        model=ConvNet(num_classes=10, num_channels=1),
        data_loader=client_loader,
        device=device,
        lr=0.05
    )
    clients.append(client)

pretrain_start = time.time()
for round_idx in range(10):
    global_params = server.get_model_parameters()
    client_models = []
    client_weights = []

    for client in clients:
        client.set_model_parameters(global_params)
        client.local_train(epochs=2, verbose=False)
        client_models.append(client.get_model_parameters())
        client_weights.append(client.num_samples)

    aggregated = server.aggregate(client_models, client_weights)
    server.set_model_parameters(aggregated)

pretrain_time = time.time() - pretrain_start

pretrain_test = server.evaluate(test_loader)
pretrain_forget = evaluate_model(server.model, client0_loader, device=device)

print(f"âœ“ é¢„è®­ç»ƒå®Œæˆ (è€—æ—¶: {pretrain_time:.1f}s)")
print(f"  æµ‹è¯•å‡†ç¡®ç‡: {pretrain_test['accuracy']:.2f}%")
print(f"  é—å¿˜æ•°æ®å‡†ç¡®ç‡: {pretrain_forget['accuracy']:.2f}%")

# ä¿å­˜é¢„è®­ç»ƒå‚æ•°
pretrained_params = server.get_model_parameters()

# ============================================================
# æ–¹æ³•1: No Unlearning (æœ€å·®åŸºçº¿)
# ============================================================
print("\n[3/5] æ–¹æ³•1: No Unlearning (ä¸åšä»»ä½•å¤„ç†)...")
no_unlearn_test = pretrain_test
no_unlearn_forget = pretrain_forget
print(f"âœ“ ç»“æœ:")
print(f"  æµ‹è¯•å‡†ç¡®ç‡: {no_unlearn_test['accuracy']:.2f}%")
print(f"  é—å¿˜æ•°æ®å‡†ç¡®ç‡: {no_unlearn_forget['accuracy']:.2f}%")

# ============================================================
# æ–¹æ³•2: Retrain (ç†æƒ³åŸºçº¿)
# ============================================================
print("\n[4/5] æ–¹æ³•2: Retrain (ä»å¤´é‡æ–°è®­ç»ƒ,æ’é™¤å®¢æˆ·ç«¯0)...")
retrain_model = ConvNet(num_classes=10, num_channels=1)
retrain = RetrainBaseline(retrain_model, device=device, lr=0.05)

retrain_start = time.time()
retrain.retrain(retain_loaders, rounds=10, local_epochs=2, verbose=False)
retrain_time = time.time() - retrain_start

retrain_test = retrain.evaluate(test_loader)
retrain_forget = evaluate_model(retrain.model, client0_loader, device=device)

print(f"âœ“ å®Œæˆ (è€—æ—¶: {retrain_time:.1f}s)")
print(f"  æµ‹è¯•å‡†ç¡®ç‡: {retrain_test['accuracy']:.2f}%")
print(f"  é—å¿˜æ•°æ®å‡†ç¡®ç‡: {retrain_forget['accuracy']:.2f}%")

# ============================================================
# æ–¹æ³•3: Fine-tuning
# ============================================================
print("\n[5/5] æ–¹æ³•3: Fine-tuning (åœ¨å‰©ä½™æ•°æ®ä¸Šç»§ç»­è®­ç»ƒ)...")
finetune_model = ConvNet(num_classes=10, num_channels=1)
finetune = FineTuningBaseline(finetune_model, pretrained_params, device=device, lr=0.01)

finetune_start = time.time()
finetune.finetune(retain_loaders, rounds=5, local_epochs=2, verbose=False)
finetune_time = time.time() - finetune_start

finetune_test = finetune.evaluate(test_loader)
finetune_forget = evaluate_model(finetune.model, client0_loader, device=device)

print(f"âœ“ å®Œæˆ (è€—æ—¶: {finetune_time:.1f}s)")
print(f"  æµ‹è¯•å‡†ç¡®ç‡: {finetune_test['accuracy']:.2f}%")
print(f"  é—å¿˜æ•°æ®å‡†ç¡®ç‡: {finetune_forget['accuracy']:.2f}%")

# ============================================================
# æ–¹æ³•4: FedForget (æˆ‘ä»¬çš„æ–¹æ³•)
# ============================================================
print("\næ–¹æ³•4: FedForget (åŒæ•™å¸ˆçŸ¥è¯†è’¸é¦ + åŠ¨æ€æƒé‡è°ƒæ•´)...")
print("æµ‹è¯•å¤šç»„å‚æ•°...")

fedforget_configs = [
    # (alpha, lambda_neg, lambda_forget, rounds, description)
    (0.95, 3.0, 1.5, 10, "ä¿å®ˆå‚æ•°"),
    (0.90, 5.0, 2.0, 10, "ä¸­ç­‰å‚æ•°"),
    (0.85, 8.0, 2.5, 10, "æ¿€è¿›å‚æ•°"),
]

fedforget_results = []

for alpha, lambda_neg, lambda_forget, rounds, desc in fedforget_configs:
    print(f"\n  é…ç½®: {desc}")
    print(f"    alpha={alpha}, lambda_neg={lambda_neg}, lambda_forget={lambda_forget}, rounds={rounds}")

    fedforget_server = FedForgetServer(
        model=ConvNet(num_classes=10, num_channels=1),
        device=device
    )
    fedforget_server.set_model_parameters(pretrained_params)
    fedforget_server.lambda_forget = lambda_forget

    unlearn_client = UnlearningClient(
        client_id=0,
        model=ConvNet(num_classes=10, num_channels=1),
        data_loader=client0_loader,
        device=device,
        lr=0.01
    )

    # å‡†å¤‡é—å¿˜: æ•™å¸ˆA = é¢„è®­ç»ƒæ¨¡å‹(å›ºå®š)
    unlearn_client.prepare_unlearning(
        global_model_params=pretrained_params,
        local_model_params=None
    )

    fedforget_server.register_unlearning_client(0, current_round=0)
    regular_clients = [clients[1], clients[2], clients[3], clients[4]]

    fedforget_start = time.time()

    for round_idx in range(rounds):
        global_params = fedforget_server.get_model_parameters()

        # é—å¿˜å®¢æˆ·ç«¯è®­ç»ƒ
        unlearn_client.set_model_parameters(global_params)
        unlearn_client.unlearning_train(
            epochs=2,
            method='dual_teacher',
            distill_temp=2.0,
            alpha=alpha,
            lambda_pos=1.0,
            lambda_neg=lambda_neg,
            verbose=False
        )

        # éšæœºé€‰æ‹©2ä¸ªå¸¸è§„å®¢æˆ·ç«¯
        selected_regular = np.random.choice(regular_clients, 2, replace=False)

        client_models = [unlearn_client.get_model_parameters()]
        client_ids = [0]
        client_samples = [unlearn_client.num_samples]

        for client in selected_regular:
            client.set_model_parameters(global_params)
            client.local_train(epochs=2, verbose=False)
            client_models.append(client.get_model_parameters())
            client_ids.append(client.client_id)
            client_samples.append(client.num_samples)

        # FedForgetèšåˆ
        aggregated = fedforget_server.aggregate_with_fedforget(
            client_models,
            client_ids,
            client_samples,
            current_round=round_idx
        )
        fedforget_server.set_model_parameters(aggregated)

    fedforget_time = time.time() - fedforget_start

    fedforget_test = fedforget_server.evaluate(test_loader)
    fedforget_forget = evaluate_model(fedforget_server.model, client0_loader, device=device)

    print(f"  âœ“ å®Œæˆ (è€—æ—¶: {fedforget_time:.1f}s)")
    print(f"    æµ‹è¯•å‡†ç¡®ç‡: {fedforget_test['accuracy']:.2f}%")
    print(f"    é—å¿˜æ•°æ®å‡†ç¡®ç‡: {fedforget_forget['accuracy']:.2f}%")

    fedforget_results.append({
        'config': desc,
        'alpha': alpha,
        'lambda_neg': lambda_neg,
        'lambda_forget': lambda_forget,
        'test_acc': fedforget_test['accuracy'],
        'forget_acc': fedforget_forget['accuracy'],
        'time': fedforget_time
    })

# ============================================================
# ç»“æœæ±‡æ€»
# ============================================================
print("\n" + "="*80)
print("å®Œæ•´å¯¹æ¯”ç»“æœ")
print("="*80)

print("\né¢„è®­ç»ƒåŸºçº¿:")
print(f"  æµ‹è¯•å‡†ç¡®ç‡: {pretrain_test['accuracy']:.2f}%")
print(f"  é—å¿˜æ•°æ®å‡†ç¡®ç‡: {pretrain_forget['accuracy']:.2f}%")

print("\n" + "-"*80)
print(f"{'æ–¹æ³•':<20} {'æµ‹è¯•å‡†ç¡®ç‡':<12} {'é—å¿˜å‡†ç¡®ç‡':<12} {'ä¿æŒç‡':<10} {'é—å¿˜ç‡':<10} {'è€—æ—¶':<8}")
print("-"*80)

methods = [
    ("No Unlearning", no_unlearn_test['accuracy'], no_unlearn_forget['accuracy'], 0.0),
    ("Retrain (ç†æƒ³)", retrain_test['accuracy'], retrain_forget['accuracy'], retrain_time),
    ("Fine-tuning", finetune_test['accuracy'], finetune_forget['accuracy'], finetune_time),
]

for method_name, test_acc, forget_acc, exec_time in methods:
    retention = test_acc / pretrain_test['accuracy'] * 100
    forgetting = (pretrain_forget['accuracy'] - forget_acc) / pretrain_forget['accuracy'] * 100

    print(f"{method_name:<20} {test_acc:>6.2f}%      {forget_acc:>6.2f}%      "
          f"{retention:>5.1f}%     {forgetting:>5.1f}%     {exec_time:>5.1f}s")

print("-"*80)

for result in fedforget_results:
    method_name = f"FedForget ({result['config']})"
    test_acc = result['test_acc']
    forget_acc = result['forget_acc']
    exec_time = result['time']

    retention = test_acc / pretrain_test['accuracy'] * 100
    forgetting = (pretrain_forget['accuracy'] - forget_acc) / pretrain_forget['accuracy'] * 100

    print(f"{method_name:<20} {test_acc:>6.2f}%      {forget_acc:>6.2f}%      "
          f"{retention:>5.1f}%     {forgetting:>5.1f}%     {exec_time:>5.1f}s")

print("="*80)

# ============================================================
# æˆåŠŸè¯„ä¼°
# ============================================================
print("\nè¯„ä¼°æ ‡å‡†: æµ‹è¯•å‡†ç¡®ç‡ä¿æŒ>90%, é—å¿˜æ•°æ®å‡†ç¡®ç‡<60%")
print("-"*80)

for method_name, test_acc, forget_acc, _ in methods[1:]:  # æ’é™¤No Unlearning
    retention = test_acc / pretrain_test['accuracy']
    success = retention > 0.90 and forget_acc < 60.0

    status = "âœ…" if success else "âš ï¸"
    print(f"{status} {method_name:<20} ä¿æŒç‡: {retention*100:.1f}%, é—å¿˜å‡†ç¡®ç‡: {forget_acc:.2f}%")

for result in fedforget_results:
    method_name = f"FedForget ({result['config']})"
    test_acc = result['test_acc']
    forget_acc = result['forget_acc']

    retention = test_acc / pretrain_test['accuracy']
    success = retention > 0.90 and forget_acc < 60.0

    status = "âœ…" if success else "âš ï¸"
    print(f"{status} {method_name:<20} ä¿æŒç‡: {retention*100:.1f}%, é—å¿˜å‡†ç¡®ç‡: {forget_acc:.2f}%")

print("="*80)

# ============================================================
# æœ€ä½³FedForgeté…ç½®
# ============================================================
best_fedforget = min(fedforget_results, key=lambda x: x['forget_acc'])
best_retention = best_fedforget['test_acc'] / pretrain_test['accuracy']

print("\næœ€ä½³FedForgeté…ç½®:")
print(f"  é…ç½®: {best_fedforget['config']}")
print(f"  alpha={best_fedforget['alpha']}, lambda_neg={best_fedforget['lambda_neg']}, "
      f"lambda_forget={best_fedforget['lambda_forget']}")
print(f"  æµ‹è¯•å‡†ç¡®ç‡: {best_fedforget['test_acc']:.2f}% (ä¿æŒç‡: {best_retention*100:.1f}%)")
print(f"  é—å¿˜å‡†ç¡®ç‡: {best_fedforget['forget_acc']:.2f}%")

if best_retention > 0.90 and best_fedforget['forget_acc'] < 60.0:
    print("\nğŸ‰ FedForgetæˆåŠŸè¾¾åˆ°ç›®æ ‡!")
else:
    print("\nğŸ’¡ FedForgetéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
    if best_retention <= 0.90:
        print("   - æµ‹è¯•å‡†ç¡®ç‡ä¿æŒä¸è¶³,å»ºè®®å¢å¤§alpha")
    if best_fedforget['forget_acc'] >= 60.0:
        print("   - é—å¿˜æ•ˆæœä¸è¶³,å»ºè®®å¢å¤§lambda_negæˆ–lambda_forget")

print("\nå®éªŒå®Œæˆ!")
