#!/usr/bin/env python3
"""
è¯„ä¼°Day 2æœ€ä½³é…ç½®çš„MIAè¡¨ç°

é…ç½®: alpha=0.93, lambda_neg=3.5, lambda_forget=2.0
é¢„æœŸ: æ›´é«˜çš„é—å¿˜ç‡(40.4%)ï¼Œæ£€éªŒéšç§ä¿æŠ¤æ˜¯å¦ä»ç„¶è‰¯å¥½
"""

import sys
sys.path.append('/home/featurize/work/GJC/fedforget')

import torch
import numpy as np
import copy

from src.data import load_federated_data
from src.models import ConvNet
from src.federated import Client, Server
from src.federated.server import FedForgetServer
from src.federated.client import UnlearningClient
from src.utils.metrics import evaluate_model
from src.utils.mia import evaluate_unlearning_privacy
from torch.utils.data import ConcatDataset, DataLoader

torch.manual_seed(42)
np.random.seed(42)
device = 'cuda' if torch.cuda.is_available() else 'cpu'

print("="*80)
print("æœ€ä½³é…ç½®MIAè¯„ä¼°: alpha=0.93, lambda_neg=3.5")
print("="*80)

# ============================================================
# æ•°æ®å‡†å¤‡
# ============================================================
print("\n[1/3] æ•°æ®åŠ è½½...")

fed_data = load_federated_data(
    dataset_name='cifar10',
    num_clients=5,
    data_dist='noniid',
    dirichlet_alpha=0.5,
    data_root='/home/featurize/data'
)

test_loader = fed_data.get_test_loader(batch_size=256)
client0_loader = fed_data.get_client_loader(0, batch_size=64)

# ä¿ç•™æ•°æ®
retain_datasets = [fed_data.get_client_dataset(i) for i in range(1, 5)]
retain_combined = ConcatDataset(retain_datasets)
retain_loader = DataLoader(retain_combined, batch_size=64, shuffle=False)

print(f"âœ“ æ•°æ®åŠ è½½å®Œæˆ")

# ============================================================
# é¢„è®­ç»ƒ
# ============================================================
print("\n[2/3] é¢„è®­ç»ƒ...")

model = ConvNet(num_classes=10, num_channels=3)
server = Server(model=model, device=device)

clients = []
for i in range(5):
    client_loader = fed_data.get_client_loader(i, batch_size=64)
    client = Client(i, ConvNet(num_classes=10, num_channels=3), client_loader, device, lr=0.01)
    clients.append(client)

for round_idx in range(20):
    global_params = server.get_model_parameters()
    client_models = []
    client_weights = []

    for client in clients:
        client.set_model_parameters(global_params)
        client.local_train(epochs=2, verbose=False)
        client_models.append(client.get_model_parameters())
        client_weights.append(client.num_samples)

    aggregated = server.aggregate(client_models, client_weights)
    server.set_model_parameters(aggregated)

pretrain_test = server.evaluate(test_loader)
pretrain_forget = evaluate_model(server.model, client0_loader, device=device)

print(f"âœ“ é¢„è®­ç»ƒå®Œæˆ")
print(f"  æµ‹è¯•å‡†ç¡®ç‡: {pretrain_test['accuracy']:.2f}%")
print(f"  é—å¿˜æ•°æ®å‡†ç¡®ç‡: {pretrain_forget['accuracy']:.2f}%")

pretrained_params = copy.deepcopy(server.get_model_parameters())

# ============================================================
# è¯„ä¼°: æœ€ä½³é…ç½® (alpha=0.93, lambda_neg=3.5)
# ============================================================
print("\n[3/3] è¯„ä¼°æœ€ä½³é…ç½®...")
print("\n" + "-"*80)
print("FedForget: alpha=0.93, lambda_neg=3.5, lambda_forget=2.0")
print("-"*80)

fedforget_server = FedForgetServer(
    model=ConvNet(num_classes=10, num_channels=3),
    device=device
)
fedforget_server.set_model_parameters(copy.deepcopy(pretrained_params))
fedforget_server.lambda_forget = 2.0  # ä½¿ç”¨Day 2æœ€ä½³é…ç½®

unlearn_client = UnlearningClient(
    client_id=0,
    model=ConvNet(num_classes=10, num_channels=3),
    data_loader=client0_loader,
    device=device,
    lr=0.005
)

unlearn_client.prepare_unlearning(
    global_model_params=copy.deepcopy(pretrained_params),
    local_model_params=None
)

fedforget_server.register_unlearning_client(0, current_round=0)
regular_clients = [clients[1], clients[2], clients[3], clients[4]]

print("\né—å¿˜è®­ç»ƒè¿›åº¦:")
for round_idx in range(10):
    global_params = fedforget_server.get_model_parameters()

    unlearn_client.set_model_parameters(global_params)
    unlearn_client.unlearning_train(
        epochs=2,
        method='dual_teacher',
        distill_temp=2.0,
        alpha=0.93,  # Day 2æœ€ä½³
        lambda_pos=1.0,
        lambda_neg=3.5,  # Day 2æœ€ä½³
        verbose=False
    )

    selected_regular = np.random.choice(regular_clients, 2, replace=False)

    client_models = [unlearn_client.get_model_parameters()]
    client_ids = [0]
    client_samples = [unlearn_client.num_samples]

    for client in selected_regular:
        client.set_model_parameters(global_params)
        client.local_train(epochs=2, verbose=False)
        client_models.append(client.get_model_parameters())
        client_ids.append(client.client_id)
        client_samples.append(client.num_samples)

    aggregated = fedforget_server.aggregate_with_fedforget(
        client_models,
        client_ids,
        client_samples,
        current_round=round_idx
    )
    fedforget_server.set_model_parameters(aggregated)

    # æ¯è½®è¯„ä¼°
    if (round_idx + 1) % 3 == 0:
        temp_test = fedforget_server.evaluate(test_loader)
        temp_forget = evaluate_model(fedforget_server.model, client0_loader, device=device)
        print(f"  Round {round_idx+1}: Test {temp_test['accuracy']:.2f}%, Forget {temp_forget['accuracy']:.2f}%")

# æœ€ç»ˆè¯„ä¼°
test_results = fedforget_server.evaluate(test_loader)
forget_results = evaluate_model(fedforget_server.model, client0_loader, device=device)

retention = test_results['accuracy'] / pretrain_test['accuracy']
forgetting = (pretrain_forget['accuracy'] - forget_results['accuracy']) / pretrain_forget['accuracy']

print(f"\nâœ“ é—å¿˜è®­ç»ƒå®Œæˆ")
print(f"  æµ‹è¯•å‡†ç¡®ç‡: {test_results['accuracy']:.2f}% (ä¿æŒç‡: {retention*100:.1f}%)")
print(f"  é—å¿˜å‡†ç¡®ç‡: {forget_results['accuracy']:.2f}% (é—å¿˜ç‡: {forgetting*100:.1f}%)")

# MIAè¯„ä¼°
print("\n" + "-"*80)
print("MIAéšç§è¯„ä¼°")
print("-"*80)

mia_results = evaluate_unlearning_privacy(
    fedforget_server.model,
    forget_loader=client0_loader,
    retain_loader=retain_loader,
    test_loader=test_loader,
    device=device
)

print(f"\nForget vs Test (ç†æƒ³: ASRâ‰ˆ50%, AUCâ‰ˆ0.5):")
print(f"  æ”»å‡»å‡†ç¡®ç‡ (ASR): {mia_results['forget_vs_test']['accuracy']:.2f}%")
print(f"  AUC: {mia_results['forget_vs_test']['auc']:.4f}")
print(f"  ForgetæŸå¤±: {mia_results['forget_vs_test']['forget_loss']:.4f}")
print(f"  TestæŸå¤±: {mia_results['forget_vs_test']['test_loss']:.4f}")

print(f"\nForget vs Retain:")
print(f"  æ”»å‡»å‡†ç¡®ç‡ (ASR): {mia_results['forget_vs_retain']['accuracy']:.2f}%")
print(f"  AUC: {mia_results['forget_vs_retain']['auc']:.4f}")

# ä¸Day 3é…ç½®å¯¹æ¯”
print("\n" + "="*80)
print("é…ç½®å¯¹æ¯”æ€»ç»“")
print("="*80)

print(f"\n{'é…ç½®':<20} {'Test%':<8} {'Forget%':<9} {'é—å¿˜ç‡%':<9} {'ASR%':<8} {'AUC':<8}")
print("-"*80)

# Day 3é…ç½® (alpha=0.95)
print(f"{'Day 3 (Î±=0.95)':<20} {'63.75':<8} {'61.87':<9} {'27.3':<9} {'48.41':<8} {'0.4642':<8}")

# Day 2æœ€ä½³ (alpha=0.93)
print(f"{'Day 2æœ€ä½³ (Î±=0.93)':<20} {test_results['accuracy']:<8.2f} {forget_results['accuracy']:<9.2f} "
      f"{forgetting*100:<9.1f} {mia_results['forget_vs_test']['accuracy']:<8.2f} "
      f"{mia_results['forget_vs_test']['auc']:<8.4f}")

print("="*80)

# åˆ†æ
print("\nğŸ“Š åˆ†æ:")

if forgetting * 100 > 27.3:
    print(f"âœ… é—å¿˜ç‡æå‡: {forgetting*100:.1f}% > 27.3% (Day 3)")
else:
    print(f"âš ï¸ é—å¿˜ç‡ä¸‹é™: {forgetting*100:.1f}% < 27.3% (Day 3)")

asr = mia_results['forget_vs_test']['accuracy']
if abs(asr - 50) < abs(48.41 - 50):
    print(f"âœ… éšç§ä¿æŠ¤æ›´å¥½: ASR {asr:.2f}% æ›´æ¥è¿‘50%")
elif abs(asr - 50) > abs(48.41 - 50) + 5:
    print(f"âš ï¸ éšç§ä¿æŠ¤å˜å·®: ASR {asr:.2f}% åç¦»50%è¶…è¿‡5%")
else:
    print(f"â¡ï¸ éšç§ä¿æŠ¤ç›¸å½“: ASR {asr:.2f}% vs 48.41%")

if retention * 100 > 90.6:
    print(f"âœ… æ€§èƒ½ä¿æŒæ›´å¥½: {retention*100:.1f}% > 90.6% (Day 3)")
else:
    print(f"âš ï¸ æ€§èƒ½ä¸‹é™æ›´å¤š: {retention*100:.1f}% < 90.6% (Day 3)")

# ä¿å­˜ç»“æœ
import csv
import os

os.makedirs('/home/featurize/work/GJC/fedforget/results', exist_ok=True)

with open('/home/featurize/work/GJC/fedforget/results/best_config_mia.csv', 'w', newline='') as f:
    writer = csv.writer(f)
    writer.writerow(['Config', 'Alpha', 'Lambda_neg', 'Lambda_forget',
                    'Test_Acc', 'Forget_Acc', 'Forgetting_Rate',
                    'ASR_Forget_vs_Test', 'AUC_Forget_vs_Test'])

    writer.writerow([
        'Day2_Best', 0.93, 3.5, 2.0,
        test_results['accuracy'],
        forget_results['accuracy'],
        forgetting * 100,
        mia_results['forget_vs_test']['accuracy'],
        mia_results['forget_vs_test']['auc']
    ])

print(f"\nâœ“ ç»“æœå·²ä¿å­˜åˆ°: results/best_config_mia.csv")
print("\nå®éªŒå®Œæˆ!")
