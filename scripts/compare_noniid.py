#!/usr/bin/env python3
"""
Non-IIDè®¾ç½®ä¸‹çš„é—å¿˜å¯¹æ¯”å®éªŒ

å…³é”®æ”¹è¿›:
1. ä½¿ç”¨Non-IIDæ•°æ®åˆ†å¸ƒ (Dirichlet alpha=0.1)
2. é—å¿˜å®¢æˆ·ç«¯æ‹¥æœ‰ç‰¹å®šç±»åˆ«çš„æ›´å¤šæ•°æ®
3. è¿™æ ·é—å¿˜å,æ¨¡å‹åœ¨è¿™äº›ç±»åˆ«ä¸Šçš„å‡†ç¡®ç‡åº”è¯¥ä¸‹é™

ç›®æ ‡: åˆ›é€ ä¸€ä¸ªçœŸæ­£å¯é—å¿˜çš„åœºæ™¯
"""

import sys
sys.path.append('/home/featurize/work/GJC/fedforget')

import torch
import numpy as np
import time

from src.data import load_federated_data
from src.models import ConvNet
from src.federated import Client, Server
from src.federated.server import FedForgetServer
from src.federated.client import UnlearningClient
from src.unlearning.baselines import RetrainBaseline, FineTuningBaseline
from src.utils.metrics import evaluate_model, compute_class_accuracy

# å›ºå®šéšæœºç§å­
torch.manual_seed(42)
np.random.seed(42)
device = 'cuda' if torch.cuda.is_available() else 'cpu'

print("="*80)
print("Non-IIDè®¾ç½®ä¸‹çš„æœºå™¨é—å¿˜å¯¹æ¯”å®éªŒ")
print("="*80)

# ============================================================
# æ•°æ®å‡†å¤‡ - Non-IID
# ============================================================
print("\n[1/5] æ•°æ®åŠ è½½ (Non-IID, Dirichlet alpha=0.1)...")
fed_data = load_federated_data(
    dataset_name='mnist',
    num_clients=5,
    data_dist='noniid',  # å…³é”®: Non-IIDåˆ†å¸ƒ (æ³¨æ„æ˜¯'noniid'ä¸æ˜¯'non-iid')
    dirichlet_alpha=0.1,  # å°alpha = æ›´ä¸å¹³è¡¡
    data_root='/home/featurize/data'
)

test_loader = fed_data.get_test_loader(batch_size=256)
client0_loader = fed_data.get_client_loader(0, batch_size=64)  # é—å¿˜å®¢æˆ·ç«¯
retain_loaders = [fed_data.get_client_loader(i, batch_size=64) for i in [1, 2, 3, 4]]

print(f"âœ“ æ•°æ®åŠ è½½å®Œæˆ")
print(f"  æ€»å®¢æˆ·ç«¯æ•°: 5")
print(f"  é—å¿˜å®¢æˆ·ç«¯: 0")
print(f"  ä¿ç•™å®¢æˆ·ç«¯: 1, 2, 3, 4")
print(f"  æ•°æ®åˆ†å¸ƒ: Non-IID (Dirichlet alpha=0.1)")

# ============================================================
# é¢„è®­ç»ƒ
# ============================================================
print("\n[2/5] é¢„è®­ç»ƒæ¨¡å‹ (10è½®)...")
model = ConvNet(num_classes=10, num_channels=1)
server = Server(model=model, device=device)

clients = []
for i in range(5):
    client_loader = fed_data.get_client_loader(i, batch_size=64)
    client = Client(
        client_id=i,
        model=ConvNet(num_classes=10, num_channels=1),
        data_loader=client_loader,
        device=device,
        lr=0.05
    )
    clients.append(client)

pretrain_start = time.time()
for round_idx in range(10):
    global_params = server.get_model_parameters()
    client_models = []
    client_weights = []

    for client in clients:
        client.set_model_parameters(global_params)
        client.local_train(epochs=2, verbose=False)
        client_models.append(client.get_model_parameters())
        client_weights.append(client.num_samples)

    aggregated = server.aggregate(client_models, client_weights)
    server.set_model_parameters(aggregated)

pretrain_time = time.time() - pretrain_start

pretrain_test = server.evaluate(test_loader)
pretrain_forget = evaluate_model(server.model, client0_loader, device=device)

# åˆ†æå„ç±»åˆ«å‡†ç¡®ç‡
pretrain_class_acc = compute_class_accuracy(server.model, client0_loader, num_classes=10, device=device)

print(f"âœ“ é¢„è®­ç»ƒå®Œæˆ (è€—æ—¶: {pretrain_time:.1f}s)")
print(f"  æµ‹è¯•å‡†ç¡®ç‡: {pretrain_test['accuracy']:.2f}%")
print(f"  é—å¿˜æ•°æ®å‡†ç¡®ç‡: {pretrain_forget['accuracy']:.2f}%")
print(f"\n  å®¢æˆ·ç«¯0å„ç±»åˆ«å‡†ç¡®ç‡:")
for class_id, acc in pretrain_class_acc.items():
    print(f"    ç±»åˆ« {class_id}: {acc:.2f}%")

# ä¿å­˜é¢„è®­ç»ƒå‚æ•°
pretrained_params = server.get_model_parameters()

# ============================================================
# æ–¹æ³•1: No Unlearning
# ============================================================
print("\n[3/5] æ–¹æ³•1: No Unlearning (ä¸åšä»»ä½•å¤„ç†)...")
no_unlearn_test = pretrain_test
no_unlearn_forget = pretrain_forget
print(f"âœ“ ç»“æœ:")
print(f"  æµ‹è¯•å‡†ç¡®ç‡: {no_unlearn_test['accuracy']:.2f}%")
print(f"  é—å¿˜æ•°æ®å‡†ç¡®ç‡: {no_unlearn_forget['accuracy']:.2f}%")

# ============================================================
# æ–¹æ³•2: Retrain
# ============================================================
print("\n[4/5] æ–¹æ³•2: Retrain (ä»å¤´é‡æ–°è®­ç»ƒ,æ’é™¤å®¢æˆ·ç«¯0)...")
retrain_model = ConvNet(num_classes=10, num_channels=1)
retrain = RetrainBaseline(retrain_model, device=device, lr=0.05)

retrain_start = time.time()
retrain.retrain(retain_loaders, rounds=10, local_epochs=2, verbose=False)
retrain_time = time.time() - retrain_start

retrain_test = retrain.evaluate(test_loader)
retrain_forget = evaluate_model(retrain.model, client0_loader, device=device)
retrain_class_acc = compute_class_accuracy(retrain.model, client0_loader, num_classes=10, device=device)

print(f"âœ“ å®Œæˆ (è€—æ—¶: {retrain_time:.1f}s)")
print(f"  æµ‹è¯•å‡†ç¡®ç‡: {retrain_test['accuracy']:.2f}%")
print(f"  é—å¿˜æ•°æ®å‡†ç¡®ç‡: {retrain_forget['accuracy']:.2f}%")
print(f"\n  å®¢æˆ·ç«¯0å„ç±»åˆ«å‡†ç¡®ç‡:")
for class_id, acc in retrain_class_acc.items():
    print(f"    ç±»åˆ« {class_id}: {acc:.2f}%")

# ============================================================
# æ–¹æ³•3: Fine-tuning
# ============================================================
print("\n[5/5] æ–¹æ³•3: Fine-tuning (åœ¨å‰©ä½™æ•°æ®ä¸Šç»§ç»­è®­ç»ƒ)...")
finetune_model = ConvNet(num_classes=10, num_channels=1)
finetune = FineTuningBaseline(finetune_model, pretrained_params, device=device, lr=0.01)

finetune_start = time.time()
finetune.finetune(retain_loaders, rounds=5, local_epochs=2, verbose=False)
finetune_time = time.time() - finetune_start

finetune_test = finetune.evaluate(test_loader)
finetune_forget = evaluate_model(finetune.model, client0_loader, device=device)
finetune_class_acc = compute_class_accuracy(finetune.model, client0_loader, num_classes=10, device=device)

print(f"âœ“ å®Œæˆ (è€—æ—¶: {finetune_time:.1f}s)")
print(f"  æµ‹è¯•å‡†ç¡®ç‡: {finetune_test['accuracy']:.2f}%")
print(f"  é—å¿˜æ•°æ®å‡†ç¡®ç‡: {finetune_forget['accuracy']:.2f}%")
print(f"\n  å®¢æˆ·ç«¯0å„ç±»åˆ«å‡†ç¡®ç‡:")
for class_id, acc in finetune_class_acc.items():
    print(f"    ç±»åˆ« {class_id}: {acc:.2f}%")

# ============================================================
# æ–¹æ³•4: FedForget
# ============================================================
print("\næ–¹æ³•4: FedForget (åŒæ•™å¸ˆçŸ¥è¯†è’¸é¦ + åŠ¨æ€æƒé‡è°ƒæ•´)...")
print("æµ‹è¯•ä¿å®ˆå‚æ•°...")

fedforget_server = FedForgetServer(
    model=ConvNet(num_classes=10, num_channels=1),
    device=device
)
fedforget_server.set_model_parameters(pretrained_params)
fedforget_server.lambda_forget = 1.5

unlearn_client = UnlearningClient(
    client_id=0,
    model=ConvNet(num_classes=10, num_channels=1),
    data_loader=client0_loader,
    device=device,
    lr=0.01
)

# å‡†å¤‡é—å¿˜
unlearn_client.prepare_unlearning(
    global_model_params=pretrained_params,
    local_model_params=None
)

fedforget_server.register_unlearning_client(0, current_round=0)
regular_clients = [clients[1], clients[2], clients[3], clients[4]]

fedforget_start = time.time()

for round_idx in range(10):
    global_params = fedforget_server.get_model_parameters()

    # é—å¿˜å®¢æˆ·ç«¯è®­ç»ƒ
    unlearn_client.set_model_parameters(global_params)
    unlearn_client.unlearning_train(
        epochs=2,
        method='dual_teacher',
        distill_temp=2.0,
        alpha=0.95,
        lambda_pos=1.0,
        lambda_neg=3.0,
        verbose=False
    )

    # éšæœºé€‰æ‹©2ä¸ªå¸¸è§„å®¢æˆ·ç«¯
    selected_regular = np.random.choice(regular_clients, 2, replace=False)

    client_models = [unlearn_client.get_model_parameters()]
    client_ids = [0]
    client_samples = [unlearn_client.num_samples]

    for client in selected_regular:
        client.set_model_parameters(global_params)
        client.local_train(epochs=2, verbose=False)
        client_models.append(client.get_model_parameters())
        client_ids.append(client.client_id)
        client_samples.append(client.num_samples)

    # FedForgetèšåˆ
    aggregated = fedforget_server.aggregate_with_fedforget(
        client_models,
        client_ids,
        client_samples,
        current_round=round_idx
    )
    fedforget_server.set_model_parameters(aggregated)

fedforget_time = time.time() - fedforget_start

fedforget_test = fedforget_server.evaluate(test_loader)
fedforget_forget = evaluate_model(fedforget_server.model, client0_loader, device=device)
fedforget_class_acc = compute_class_accuracy(fedforget_server.model, client0_loader, num_classes=10, device=device)

print(f"âœ“ å®Œæˆ (è€—æ—¶: {fedforget_time:.1f}s)")
print(f"  æµ‹è¯•å‡†ç¡®ç‡: {fedforget_test['accuracy']:.2f}%")
print(f"  é—å¿˜æ•°æ®å‡†ç¡®ç‡: {fedforget_forget['accuracy']:.2f}%")
print(f"\n  å®¢æˆ·ç«¯0å„ç±»åˆ«å‡†ç¡®ç‡:")
for class_id, acc in fedforget_class_acc.items():
    print(f"    ç±»åˆ« {class_id}: {acc:.2f}%")

# ============================================================
# ç»“æœå¯¹æ¯”
# ============================================================
print("\n" + "="*80)
print("å®Œæ•´å¯¹æ¯”ç»“æœ (Non-IIDè®¾ç½®)")
print("="*80)

print("\né¢„è®­ç»ƒåŸºçº¿:")
print(f"  æµ‹è¯•å‡†ç¡®ç‡: {pretrain_test['accuracy']:.2f}%")
print(f"  é—å¿˜æ•°æ®å‡†ç¡®ç‡: {pretrain_forget['accuracy']:.2f}%")

print("\n" + "-"*80)
print(f"{'æ–¹æ³•':<20} {'æµ‹è¯•å‡†ç¡®ç‡':<12} {'é—å¿˜å‡†ç¡®ç‡':<12} {'ä¿æŒç‡':<10} {'é—å¿˜ç‡':<10} {'è€—æ—¶':<8}")
print("-"*80)

methods = [
    ("No Unlearning", no_unlearn_test['accuracy'], no_unlearn_forget['accuracy'], 0.0),
    ("Retrain (ç†æƒ³)", retrain_test['accuracy'], retrain_forget['accuracy'], retrain_time),
    ("Fine-tuning", finetune_test['accuracy'], finetune_forget['accuracy'], finetune_time),
    ("FedForget", fedforget_test['accuracy'], fedforget_forget['accuracy'], fedforget_time),
]

for method_name, test_acc, forget_acc, exec_time in methods:
    retention = test_acc / pretrain_test['accuracy'] * 100
    forgetting = (pretrain_forget['accuracy'] - forget_acc) / pretrain_forget['accuracy'] * 100

    print(f"{method_name:<20} {test_acc:>6.2f}%      {forget_acc:>6.2f}%      "
          f"{retention:>5.1f}%     {forgetting:>5.1f}%     {exec_time:>5.1f}s")

print("="*80)

# ============================================================
# å„ç±»åˆ«é—å¿˜æ•ˆæœåˆ†æ
# ============================================================
print("\n" + "="*80)
print("å„ç±»åˆ«é—å¿˜æ•ˆæœåˆ†æ")
print("="*80)

print("\nå„æ–¹æ³•åœ¨å®¢æˆ·ç«¯0æ•°æ®ä¸Šçš„ç±»åˆ«å‡†ç¡®ç‡å¯¹æ¯”:")
print("-"*80)
print(f"{'ç±»åˆ«':<8} {'é¢„è®­ç»ƒ':<10} {'Retrain':<10} {'Fine-tune':<10} {'FedForget':<10}")
print("-"*80)

for class_id in range(10):
    pretrain_acc = pretrain_class_acc[class_id]
    retrain_acc = retrain_class_acc[class_id]
    finetune_acc = finetune_class_acc[class_id]
    fedforget_acc = fedforget_class_acc[class_id]

    print(f"{class_id:<8} {pretrain_acc:>6.2f}%   {retrain_acc:>6.2f}%   "
          f"{finetune_acc:>6.2f}%   {fedforget_acc:>6.2f}%")

print("="*80)

# ============================================================
# æˆåŠŸè¯„ä¼°
# ============================================================
print("\nè¯„ä¼°æ ‡å‡†: æµ‹è¯•å‡†ç¡®ç‡ä¿æŒ>90%, é—å¿˜æ•°æ®å‡†ç¡®ç‡ä¸‹é™>10%")
print("-"*80)

for method_name, test_acc, forget_acc, _ in methods[1:]:
    retention = test_acc / pretrain_test['accuracy']
    forgetting_ratio = (pretrain_forget['accuracy'] - forget_acc) / pretrain_forget['accuracy']
    success = retention > 0.90 and forgetting_ratio > 0.10

    status = "âœ…" if success else "âš ï¸"
    print(f"{status} {method_name:<20} ä¿æŒç‡: {retention*100:.1f}%, é—å¿˜ç‡: {forgetting_ratio*100:.1f}%")

print("="*80)

print("\nğŸ’¡ Non-IIDè®¾ç½®åˆ†æ:")
print("   - Non-IIDæ•°æ®åˆ†å¸ƒä½¿å¾—ä¸åŒå®¢æˆ·ç«¯æ‹¥æœ‰ä¸åŒçš„æ•°æ®ç‰¹å¾")
print("   - é—å¿˜å®¢æˆ·ç«¯0å,æ¨¡å‹åœ¨å…¶ç‰¹å®šç±»åˆ«ä¸Šçš„å‡†ç¡®ç‡åº”è¯¥ä¸‹é™")
print("   - RetrainåŸºçº¿å±•ç¤ºäº†ç†æƒ³çš„é—å¿˜æ•ˆæœ")
print("   - FedForgetåº”è¯¥æ¥è¿‘Retrainçš„é—å¿˜æ•ˆæœ,åŒæ—¶ä¿æŒæ›´é«˜çš„æ•ˆç‡")

print("\nå®éªŒå®Œæˆ!")
