#!/usr/bin/env python3
"""
CIFAR-10æ•°æ®é›†ä¸Šçš„é—å¿˜å¯¹æ¯”å®éªŒ

CIFAR-10ç‰¹ç‚¹:
- 32x32å½©è‰²å›¾åƒ
- 10ä¸ªç±»åˆ«: é£æœºã€æ±½è½¦ã€é¸Ÿã€çŒ«ã€é¹¿ã€ç‹—ã€é’è›™ã€é©¬ã€èˆ¹ã€å¡è½¦
- æ¯”MNISTå¤æ‚å¾—å¤š,æ³›åŒ–æ€§åº”è¯¥æ›´å¼±
- ç†è®ºä¸Šåº”è¯¥æœ‰æ›´å¥½çš„é—å¿˜æ•ˆæœ

å®éªŒè®¾ç½®:
- Non-IID (Dirichlet alpha=0.5)
- 5ä¸ªå®¢æˆ·ç«¯,é—å¿˜å®¢æˆ·ç«¯0
- å¯¹æ¯”Retrain, Fine-tuning, FedForget
"""

import sys
sys.path.append('/home/featurize/work/GJC/fedforget')

import torch
import numpy as np
import time

from src.data import load_federated_data
from src.models import ConvNet
from src.federated import Client, Server
from src.federated.server import FedForgetServer
from src.federated.client import UnlearningClient
from src.unlearning.baselines import RetrainBaseline, FineTuningBaseline
from src.utils.metrics import evaluate_model, compute_class_accuracy

# å›ºå®šéšæœºç§å­
torch.manual_seed(42)
np.random.seed(42)
device = 'cuda' if torch.cuda.is_available() else 'cpu'

print("="*80)
print("CIFAR-10æ•°æ®é›†ä¸Šçš„æœºå™¨é—å¿˜å¯¹æ¯”å®éªŒ")
print("="*80)

# ============================================================
# æ•°æ®å‡†å¤‡
# ============================================================
print("\n[1/5] æ•°æ®åŠ è½½ (CIFAR-10, Non-IID, Dirichlet alpha=0.5)...")
fed_data = load_federated_data(
    dataset_name='cifar10',
    num_clients=5,
    data_dist='noniid',
    dirichlet_alpha=0.5,
    data_root='/home/featurize/data'
)

test_loader = fed_data.get_test_loader(batch_size=256)
client0_loader = fed_data.get_client_loader(0, batch_size=64)
retain_loaders = [fed_data.get_client_loader(i, batch_size=64) for i in [1, 2, 3, 4]]

print(f"âœ“ æ•°æ®åŠ è½½å®Œæˆ")
print(f"  æ€»å®¢æˆ·ç«¯æ•°: 5")
print(f"  é—å¿˜å®¢æˆ·ç«¯: 0")
print(f"  ä¿ç•™å®¢æˆ·ç«¯: 1, 2, 3, 4")
print(f"  æ•°æ®åˆ†å¸ƒ: Non-IID (Dirichlet alpha=0.5)")

# åˆ†ææ•°æ®åˆ†å¸ƒ
print("\nå„å®¢æˆ·ç«¯æ•°æ®åˆ†å¸ƒ:")
print("-"*80)
class_names = ['é£æœº', 'æ±½è½¦', 'é¸Ÿ', 'çŒ«', 'é¹¿', 'ç‹—', 'é’è›™', 'é©¬', 'èˆ¹', 'å¡è½¦']

for i in range(5):
    loader = fed_data.get_client_loader(i, batch_size=1024)
    all_labels = []
    for _, labels in loader:
        all_labels.extend(labels.numpy().tolist())

    from collections import Counter
    class_counts = Counter(all_labels)

    print(f"\nå®¢æˆ·ç«¯{i} ({len(all_labels)}æ ·æœ¬):")
    for c in range(10):
        count = class_counts.get(c, 0)
        print(f"  ç±»åˆ«{c} ({class_names[c]}): {count:4d} ({count/len(all_labels)*100:5.1f}%)")

print("-"*80)

# ============================================================
# é¢„è®­ç»ƒ
# ============================================================
print("\n[2/5] é¢„è®­ç»ƒæ¨¡å‹ (20è½®, CIFAR-10éœ€è¦æ›´å¤šè½®)...")
model = ConvNet(num_classes=10, num_channels=3)  # 3é€šé“å½©è‰²å›¾åƒ
server = Server(model=model, device=device)

clients = []
for i in range(5):
    client_loader = fed_data.get_client_loader(i, batch_size=64)
    client = Client(
        client_id=i,
        model=ConvNet(num_classes=10, num_channels=3),
        data_loader=client_loader,
        device=device,
        lr=0.01  # CIFAR-10ä½¿ç”¨è¾ƒå°å­¦ä¹ ç‡
    )
    clients.append(client)

pretrain_start = time.time()
for round_idx in range(20):
    global_params = server.get_model_parameters()
    client_models = []
    client_weights = []

    for client in clients:
        client.set_model_parameters(global_params)
        client.local_train(epochs=2, verbose=False)
        client_models.append(client.get_model_parameters())
        client_weights.append(client.num_samples)

    aggregated = server.aggregate(client_models, client_weights)
    server.set_model_parameters(aggregated)

    if (round_idx + 1) % 5 == 0:
        test_results = server.evaluate(test_loader)
        print(f"  Round {round_idx+1}/20 | Test: {test_results['accuracy']:.2f}%")

pretrain_time = time.time() - pretrain_start

pretrain_test = server.evaluate(test_loader)
pretrain_forget = evaluate_model(server.model, client0_loader, device=device)
pretrain_class_acc = compute_class_accuracy(server.model, client0_loader, num_classes=10, device=device)

print(f"\nâœ“ é¢„è®­ç»ƒå®Œæˆ (è€—æ—¶: {pretrain_time:.1f}s)")
print(f"  æµ‹è¯•å‡†ç¡®ç‡: {pretrain_test['accuracy']:.2f}%")
print(f"  é—å¿˜æ•°æ®å‡†ç¡®ç‡: {pretrain_forget['accuracy']:.2f}%")
print(f"\n  å®¢æˆ·ç«¯0å„ç±»åˆ«å‡†ç¡®ç‡:")
for c in range(10):
    print(f"    {class_names[c]}: {pretrain_class_acc[c]:.2f}%")

pretrained_params = server.get_model_parameters()

# ============================================================
# æ–¹æ³•1: Retrain
# ============================================================
print("\n[3/5] æ–¹æ³•1: Retrain (ä»å¤´é‡æ–°è®­ç»ƒ,æ’é™¤å®¢æˆ·ç«¯0)...")
retrain_model = ConvNet(num_classes=10, num_channels=3)
retrain = RetrainBaseline(retrain_model, device=device, lr=0.01)

retrain_start = time.time()
retrain.retrain(retain_loaders, rounds=20, local_epochs=2, verbose=False)
retrain_time = time.time() - retrain_start

retrain_test = retrain.evaluate(test_loader)
retrain_forget = evaluate_model(retrain.model, client0_loader, device=device)
retrain_class_acc = compute_class_accuracy(retrain.model, client0_loader, num_classes=10, device=device)

print(f"âœ“ å®Œæˆ (è€—æ—¶: {retrain_time:.1f}s)")
print(f"  æµ‹è¯•å‡†ç¡®ç‡: {retrain_test['accuracy']:.2f}%")
print(f"  é—å¿˜æ•°æ®å‡†ç¡®ç‡: {retrain_forget['accuracy']:.2f}%")

# ============================================================
# æ–¹æ³•2: Fine-tuning
# ============================================================
print("\n[4/5] æ–¹æ³•2: Fine-tuning (åœ¨å‰©ä½™æ•°æ®ä¸Šç»§ç»­è®­ç»ƒ)...")
finetune_model = ConvNet(num_classes=10, num_channels=3)
finetune = FineTuningBaseline(finetune_model, pretrained_params, device=device, lr=0.005)

finetune_start = time.time()
finetune.finetune(retain_loaders, rounds=10, local_epochs=2, verbose=False)
finetune_time = time.time() - finetune_start

finetune_test = finetune.evaluate(test_loader)
finetune_forget = evaluate_model(finetune.model, client0_loader, device=device)
finetune_class_acc = compute_class_accuracy(finetune.model, client0_loader, num_classes=10, device=device)

print(f"âœ“ å®Œæˆ (è€—æ—¶: {finetune_time:.1f}s)")
print(f"  æµ‹è¯•å‡†ç¡®ç‡: {finetune_test['accuracy']:.2f}%")
print(f"  é—å¿˜æ•°æ®å‡†ç¡®ç‡: {finetune_forget['accuracy']:.2f}%")

# ============================================================
# æ–¹æ³•3: FedForget
# ============================================================
print("\n[5/5] æ–¹æ³•3: FedForget (åŒæ•™å¸ˆçŸ¥è¯†è’¸é¦)...")
fedforget_server = FedForgetServer(
    model=ConvNet(num_classes=10, num_channels=3),
    device=device
)
fedforget_server.set_model_parameters(pretrained_params)
fedforget_server.lambda_forget = 1.5

unlearn_client = UnlearningClient(
    client_id=0,
    model=ConvNet(num_classes=10, num_channels=3),
    data_loader=client0_loader,
    device=device,
    lr=0.005
)

unlearn_client.prepare_unlearning(
    global_model_params=pretrained_params,
    local_model_params=None
)

fedforget_server.register_unlearning_client(0, current_round=0)
regular_clients = [clients[1], clients[2], clients[3], clients[4]]

fedforget_start = time.time()

for round_idx in range(10):
    global_params = fedforget_server.get_model_parameters()

    unlearn_client.set_model_parameters(global_params)
    unlearn_client.unlearning_train(
        epochs=2,
        method='dual_teacher',
        distill_temp=2.0,
        alpha=0.95,
        lambda_pos=1.0,
        lambda_neg=3.0,
        verbose=False
    )

    selected_regular = np.random.choice(regular_clients, 2, replace=False)

    client_models = [unlearn_client.get_model_parameters()]
    client_ids = [0]
    client_samples = [unlearn_client.num_samples]

    for client in selected_regular:
        client.set_model_parameters(global_params)
        client.local_train(epochs=2, verbose=False)
        client_models.append(client.get_model_parameters())
        client_ids.append(client.client_id)
        client_samples.append(client.num_samples)

    aggregated = fedforget_server.aggregate_with_fedforget(
        client_models,
        client_ids,
        client_samples,
        current_round=round_idx
    )
    fedforget_server.set_model_parameters(aggregated)

fedforget_time = time.time() - fedforget_start

fedforget_test = fedforget_server.evaluate(test_loader)
fedforget_forget = evaluate_model(fedforget_server.model, client0_loader, device=device)
fedforget_class_acc = compute_class_accuracy(fedforget_server.model, client0_loader, num_classes=10, device=device)

print(f"âœ“ å®Œæˆ (è€—æ—¶: {fedforget_time:.1f}s)")
print(f"  æµ‹è¯•å‡†ç¡®ç‡: {fedforget_test['accuracy']:.2f}%")
print(f"  é—å¿˜æ•°æ®å‡†ç¡®ç‡: {fedforget_forget['accuracy']:.2f}%")

# ============================================================
# ç»“æœæ±‡æ€»
# ============================================================
print("\n" + "="*80)
print("CIFAR-10å®Œæ•´å¯¹æ¯”ç»“æœ")
print("="*80)

print("\né¢„è®­ç»ƒåŸºçº¿:")
print(f"  æµ‹è¯•å‡†ç¡®ç‡: {pretrain_test['accuracy']:.2f}%")
print(f"  é—å¿˜æ•°æ®å‡†ç¡®ç‡: {pretrain_forget['accuracy']:.2f}%")

print("\n" + "-"*80)
print(f"{'æ–¹æ³•':<20} {'æµ‹è¯•å‡†ç¡®ç‡':<12} {'é—å¿˜å‡†ç¡®ç‡':<12} {'ä¿æŒç‡':<10} {'é—å¿˜ç‡':<10} {'è€—æ—¶':<8}")
print("-"*80)

methods = [
    ("Retrain", retrain_test['accuracy'], retrain_forget['accuracy'], retrain_time),
    ("Fine-tuning", finetune_test['accuracy'], finetune_forget['accuracy'], finetune_time),
    ("FedForget", fedforget_test['accuracy'], fedforget_forget['accuracy'], fedforget_time),
]

for method_name, test_acc, forget_acc, exec_time in methods:
    retention = test_acc / pretrain_test['accuracy'] * 100
    forgetting = (pretrain_forget['accuracy'] - forget_acc) / pretrain_forget['accuracy'] * 100

    print(f"{method_name:<20} {test_acc:>6.2f}%      {forget_acc:>6.2f}%      "
          f"{retention:>5.1f}%     {forgetting:>5.1f}%     {exec_time:>5.1f}s")

print("="*80)

# ============================================================
# å„ç±»åˆ«å¯¹æ¯”
# ============================================================
print("\nå„æ–¹æ³•åœ¨å®¢æˆ·ç«¯0æ•°æ®ä¸Šçš„ç±»åˆ«å‡†ç¡®ç‡å¯¹æ¯”:")
print("-"*80)
print(f"{'ç±»åˆ«':<10} {'é¢„è®­ç»ƒ':<10} {'Retrain':<10} {'Fine-tune':<10} {'FedForget':<10} {'ä¸‹é™(Retrain)':<15}")
print("-"*80)

for c in range(10):
    pretrain_acc = pretrain_class_acc[c]
    retrain_acc = retrain_class_acc[c]
    finetune_acc = finetune_class_acc[c]
    fedforget_acc = fedforget_class_acc[c]

    drop = pretrain_acc - retrain_acc
    marker = "ğŸ”¥" if drop > 5.0 else ""

    print(f"{class_names[c]:<10} {pretrain_acc:>6.2f}%   {retrain_acc:>6.2f}%   "
          f"{finetune_acc:>6.2f}%   {fedforget_acc:>6.2f}%   {drop:>+6.2f}%  {marker}")

print("="*80)

# ============================================================
# è¯„ä¼°
# ============================================================
print("\nè¯„ä¼°æ ‡å‡†: æµ‹è¯•å‡†ç¡®ç‡ä¿æŒ>85%, é—å¿˜æ•°æ®å‡†ç¡®ç‡ä¸‹é™>10%")
print("-"*80)

for method_name, test_acc, forget_acc, _ in methods:
    retention = test_acc / pretrain_test['accuracy']
    forgetting_ratio = (pretrain_forget['accuracy'] - forget_acc) / pretrain_forget['accuracy']

    # CIFAR-10æ›´éš¾,é™ä½ä¿æŒç‡è¦æ±‚åˆ°85%
    success = retention > 0.85 and forgetting_ratio > 0.10

    status = "âœ…" if success else "âš ï¸"
    print(f"{status} {method_name:<20} ä¿æŒç‡: {retention*100:.1f}%, é—å¿˜ç‡: {forgetting_ratio*100:.1f}%")

print("="*80)

# å¯¹æ¯”MNIST
print("\nğŸ’¡ CIFAR-10 vs MNISTå¯¹æ¯”:")
print("-"*80)
print("MNIST (alpha=0.5):")
print("  Retrain: ä¿æŒç‡99.7%, é—å¿˜ç‡1.6%")
print("  FedForget: ä¿æŒç‡99.8%, é—å¿˜ç‡0.6%")
print()
print("CIFAR-10 (alpha=0.5):")
retrain_retention = retrain_test['accuracy'] / pretrain_test['accuracy']
retrain_forgetting = (pretrain_forget['accuracy'] - retrain_forget['accuracy']) / pretrain_forget['accuracy']
fedforget_retention = fedforget_test['accuracy'] / pretrain_test['accuracy']
fedforget_forgetting = (pretrain_forget['accuracy'] - fedforget_forget['accuracy']) / pretrain_forget['accuracy']

print(f"  Retrain: ä¿æŒç‡{retrain_retention*100:.1f}%, é—å¿˜ç‡{retrain_forgetting*100:.1f}%")
print(f"  FedForget: ä¿æŒç‡{fedforget_retention*100:.1f}%, é—å¿˜ç‡{fedforget_forgetting*100:.1f}%")
print()

if retrain_forgetting > 0.016:  # å¤§äºMNISTçš„1.6%
    print("âœ… CIFAR-10çš„é—å¿˜æ•ˆæœæ˜æ˜¾ä¼˜äºMNIST!")
    print("   åŸå› : CIFAR-10æ›´å¤æ‚,æ³›åŒ–æ€§æ›´å¼±,å°‘é‡æ•°æ®ä¸è¶³ä»¥å­¦å¥½æ‰€æœ‰ç±»åˆ«")
else:
    print("âš ï¸ CIFAR-10çš„é—å¿˜æ•ˆæœä»ç„¶ä¸ç†æƒ³")
    print("   å¯èƒ½éœ€è¦æ›´æ¿€è¿›çš„Non-IIDè®¾ç½®æˆ–ç±»åˆ«é—å¿˜ç­–ç•¥")

print("\nå®éªŒå®Œæˆ!")
