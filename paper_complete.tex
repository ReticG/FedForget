\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{hyperref}
\usepackage{natbib}
\usepackage[margin=1in]{geometry}

\title{FedForget: Federated Unlearning via Dual-Teacher Knowledge Distillation}

\author{
Anonymous Authors\\
Anonymous Institution\\
\texttt{anonymous@example.com}
}

\date{}

\begin{document}

\maketitle

\begin{abstract}
Federated Learning (FL) enables collaborative model training without centralizing data, but the "Right to be Forgotten" requires efficient data deletion from trained models. Existing federated unlearning methods face limitations in effectiveness, utility preservation, or privacy protection. We propose FedForget, a novel approach combining dual-teacher knowledge distillation with server-side dynamic weight adjustment. Our method employs two complementary teachers: a global teacher preserving overall model structure and a local teacher providing clean reference without the forgetting client's influence. Extensive experiments on CIFAR-10 with both 5-client and 10-client configurations demonstrate that FedForget achieves superior multi-dimensional performance: 96.57\% retention (minimal utility loss), 20.01\% forgetting rate (effective unlearning), and ASR=52.91\% (near-ideal privacy, closest to random guessing 50\%). Notably, FedForget exhibits counter-intuitive scalability—10-client configuration outperforms 5-client by +2.09\% retention and -2.68\% ASR. Ablation studies confirm that dual-teacher distillation contributes +11.54\% retention improvement over single-teacher approaches. Our work provides the first comprehensive evaluation of federated unlearning aligned with NeurIPS 2024 standards, offering a practical solution for privacy-preserving federated learning.
\end{abstract}

\section{Introduction}

Federated Learning (FL) has emerged as a promising paradigm for collaborative machine learning, enabling multiple clients to jointly train a shared global model without exposing their raw data. By keeping data decentralized and performing computation on local devices, FL addresses critical privacy concerns in domains such as healthcare, finance, and mobile applications.

However, the right to data deletion—enshrined in privacy regulations such as GDPR's "Right to be Forgotten" and CCPA—poses a significant challenge for federated learning systems. When a client requests to remove their data contribution from a trained model, the straightforward solution is to retrain the model from scratch excluding that client's data. Unfortunately, retraining is prohibitively expensive in large-scale federated settings, where training may involve hundreds or thousands of clients over days or weeks.

This challenge has motivated the development of Machine Unlearning—techniques that efficiently remove the influence of specific training data from a learned model without full retraining. While unlearning has been extensively studied in centralized settings, Federated Unlearning introduces unique challenges:

\begin{itemize}
\item \textbf{Data Heterogeneity}: Clients have Non-IID (non-identically distributed) data, making it difficult to remove specific client contributions while preserving global model utility
\item \textbf{Privacy Constraints}: The server cannot access raw client data, limiting the applicability of centralized unlearning techniques
\item \textbf{Catastrophic Forgetting}: Naive unlearning approaches (e.g., gradient ascent on forgetting data) can cause the model to forget not only the target data but also unrelated knowledge
\item \textbf{Multi-Objective Trade-off}: Balancing unlearning effectiveness, model utility preservation, privacy protection, and computational efficiency simultaneously
\end{itemize}

\subsection{Limitations of Existing Approaches}

Recent federated unlearning methods have made important progress, but face key limitations:

\textbf{Calibration-Based Methods} calibrate the global model using remaining clients' data. However, they often achieve limited unlearning effectiveness, as they do not actively remove the forgetting client's influence.

\textbf{Knowledge Distillation Methods} use the pre-trained global model as a teacher to guide unlearning. However, single-teacher distillation has a fundamental flaw: the teacher model itself contains knowledge from the forgetting client, leading to incomplete unlearning and privacy leakage.

\textbf{Feature-Based Methods} focus on removing feature-level influence via maximum mean discrepancy. While effective for specific feature-based attacks, they may not provide comprehensive privacy guarantees against diverse inference attacks.

\textbf{Common Weakness}: None of these methods achieve optimal balance across all four objectives—effectiveness, utility, privacy, and efficiency—simultaneously. More importantly, existing single-teacher distillation approaches fail to provide a "clean" reference model, limiting their unlearning completeness.

\subsection{Our Approach: FedForget}

We propose FedForget, a novel federated unlearning framework that addresses these limitations through dual-teacher knowledge distillation combined with server-side dynamic weight adjustment. Our key insight is that effective federated unlearning requires two complementary teachers—one preserving overall model structure (global teacher), and one providing "clean" reference without the forgetting client's influence (local teacher).

\textbf{Core Innovations}:

\begin{enumerate}
\item \textbf{Dual-Teacher Knowledge Distillation}: Teacher A (Global Teacher) preserves overall knowledge structure using the pre-trained global model. Teacher B (Local Teacher) provides clean reference using a model trained only on remaining clients' data. This synergistic effect prevents catastrophic forgetting while enabling precise unlearning, achieving +11.54\% retention compared to single-teacher distillation.

\item \textbf{Server-Side Dynamic Weight Adjustment}: Exponentially decay the forgetting client's aggregation weight over unlearning rounds, creating a smooth transition from pre-trained model to unlearned model. This complements client-side distillation for enhanced unlearning effectiveness.

\item \textbf{Multi-Objective Optimization}: Balanced loss function combining distillation (preservation) and negative learning (unlearning) achieves best trade-off: 20.01\% forgetting rate, 96.57\% retention, ASR≈50\% (near-ideal privacy), and 1.53-1.75× speedup over complete retraining.
\end{enumerate}

\subsection{Main Contributions}

We summarize our contributions as follows:

\begin{enumerate}
\item \textbf{Novel Method}: We propose FedForget, the first federated unlearning method leveraging dual-teacher knowledge distillation. By combining global and local teachers, we achieve superior unlearning completeness while preventing catastrophic forgetting.

\item \textbf{Comprehensive Evaluation}: We conduct extensive experiments on CIFAR-10 with both 5-client and 10-client configurations, fully aligned with NeurIPS 2024 standards. Our evaluation includes main results comparing against Retrain and FineTune baselines, ablation study quantifying each component's contribution, scalability analysis demonstrating improved performance with 10 clients, and privacy evaluation via Membership Inference Attacks.

\item \textbf{Superior Performance}: FedForget achieves the best multi-dimensional balance with 20.01±1.92\% forgetting rate (effective unlearning), 96.57±1.21\% retention (minimal performance loss), ASR=52.91±2.32\% (closest to ideal 50\%, superior to all baselines), 1.53× speedup over retraining, and lowest variance across 3 independent runs.

\item \textbf{Scalability Discovery}: Contrary to common assumptions, FedForget performs better with more clients—10-client configuration achieves +2.09\% retention improvement and -2.68\% ASR improvement over 5-client setup, demonstrating strong scalability.

\item \textbf{Theoretical Insights}: We provide theoretical analysis of convergence, privacy guarantees, and unlearning completeness, along with comprehensive ablation studies validating our design choices.
\end{enumerate}

\section{Related Work}

\subsection{Federated Learning}

Federated Learning was introduced by McMahan et al. with the FedAvg algorithm, enabling collaborative model training without centralizing data. Since then, FL has been widely adopted in mobile keyboard prediction, healthcare, and financial services.

Key challenges include communication efficiency, statistical heterogeneity (Non-IID data), and systems heterogeneity. Our work focuses on a new challenge: efficient data deletion in federated settings.

Real-world federated learning systems often face Non-IID data distributions due to different user behaviors, geographic locations, or device types. Dirichlet allocation is a widely-used method to simulate Non-IID distributions, which we adopt in our experiments ($\alpha$=0.5).

\subsection{Machine Unlearning}

Machine unlearning aims to efficiently remove the influence of specific training data from learned models. The concept was formalized by Cao \& Yang, with subsequent work developing exact and approximate unlearning methods.

\textbf{Exact Unlearning} methods like SISA partition training data and retrain only affected shards. While providing theoretical guarantees, they require significant storage and computation overhead.

\textbf{Approximate Unlearning} methods use gradient-based approaches, influence functions, or data augmentation. These methods are more efficient but provide weaker guarantees.

Most unlearning research focuses on centralized settings. Our work addresses the unique challenges of federated unlearning.

\subsection{Federated Unlearning}

FedEraser pioneered federated unlearning by calibrating the global model using remaining clients' data. However, it requires maintaining historical updates and may achieve limited unlearning effectiveness.

Subsequent work explored various approaches including gradient ascent, knowledge distillation, and feature-based methods. However, existing single-teacher distillation approaches suffer from incomplete unlearning because the teacher itself contains the forgetting client's knowledge.

\subsection{Knowledge Distillation}

Knowledge distillation transfers knowledge from a teacher model to a student model by matching soft predictions. It has been widely applied in model compression, transfer learning, and continual learning.

Recent work explored negative distillation for unlearning in centralized settings. Our dual-teacher approach extends this to federated learning, using complementary teachers for better preservation-forgetting trade-off.

\section{Methodology}

\subsection{Problem Formulation}

Consider a federated learning system with $N$ clients. Let $\mathcal{D}_i$ denote the local dataset of client $i$. The global model $\theta$ is trained collaboratively using FedAvg:
\begin{equation}
\theta^{(t+1)} = \sum_{i=1}^{N} \frac{|\mathcal{D}_i|}{|\mathcal{D}|} \theta_i^{(t)}
\end{equation}
where $\theta_i^{(t)}$ is the local model of client $i$ at round $t$, and $|\mathcal{D}| = \sum_{i=1}^{N} |\mathcal{D}_i|$ is the total data size.

After training converges, suppose client $f$ (the forgetting client) requests data deletion. The goal of federated unlearning is to obtain an unlearned model $\theta_{\text{unlearn}}$ that approximates the retrained model $\theta_{\text{retrain}}$ (trained from scratch without client $f$'s data), while satisfying:

\begin{itemize}
\item \textbf{Effectiveness}: The influence of $\mathcal{D}_f$ is removed from $\theta_{\text{unlearn}}$
\item \textbf{Utility}: Performance on remaining data is preserved
\item \textbf{Privacy}: Membership inference attacks cannot distinguish forgetting data from test data
\item \textbf{Efficiency}: Computation cost is significantly lower than retraining
\end{itemize}

\subsection{FedForget Framework}

FedForget combines client-side dual-teacher knowledge distillation with server-side dynamic weight adjustment.

\subsubsection{Teacher A: Global Teacher}

Teacher A is the pre-trained global model $\theta_A = \theta_{\text{pretrain}}$, which preserves the overall knowledge structure learned from all clients. It remains fixed throughout the unlearning process.

\subsubsection{Teacher B: Local Teacher}

Teacher B is a model $\theta_B$ trained only on the remaining clients' data (excluding client $f$). It serves as a "clean" reference model that does not contain client $f$'s knowledge. In practice, we train Teacher B using a few rounds of federated averaging on clients $\{1, \ldots, N\} \setminus \{f\}$.

\subsubsection{Dual-Teacher Distillation Loss}

The forgetting client minimizes a combined loss:
\begin{equation}
\mathcal{L}_{\text{total}} = \alpha \mathcal{L}_{\text{pos}}(\theta, \theta_A) - (1-\alpha) \lambda_{\text{neg}} \mathcal{L}_{\text{neg}}(\theta, \theta_B)
\end{equation}
where:
\begin{itemize}
\item $\mathcal{L}_{\text{pos}}$ is the positive distillation loss (KL divergence) from Teacher A, preserving overall structure
\item $\mathcal{L}_{\text{neg}}$ is the negative distillation loss (KL divergence) from Teacher B, removing forgetting client's influence
\item $\alpha \in [0,1]$ balances preservation vs. forgetting
\item $\lambda_{\text{neg}} > 0$ controls forgetting strength
\end{itemize}

The positive distillation loss is:
\begin{equation}
\mathcal{L}_{\text{pos}}(\theta, \theta_A) = \text{KL}(f_\theta(\mathbf{x}) \| f_{\theta_A}(\mathbf{x}))
\end{equation}

The negative distillation loss is:
\begin{equation}
\mathcal{L}_{\text{neg}}(\theta, \theta_B) = \text{KL}(f_\theta(\mathbf{x}) \| f_{\theta_B}(\mathbf{x}))
\end{equation}

\subsection{Server-Side Dynamic Weight Adjustment}

To further enhance unlearning, the server dynamically adjusts the forgetting client's aggregation weight using exponential decay:
\begin{equation}
w_f^{(t)} = w_f^{(0)} \cdot \exp(-\lambda_{\text{forget}} \cdot t)
\end{equation}
where $\lambda_{\text{forget}} > 0$ controls the decay rate. This gradually reduces the forgetting client's influence during unlearning rounds.

The aggregation becomes:
\begin{equation}
\theta^{(t+1)} = \frac{\sum_{i=1}^{N} w_i^{(t)} \theta_i^{(t)}}{\sum_{i=1}^{N} w_i^{(t)}}
\end{equation}
where $w_i^{(t)} = |\mathcal{D}_i|$ for regular clients and $w_f^{(t)}$ as defined above for the forgetting client.

\subsection{Algorithm}

The complete FedForget algorithm is shown in Algorithm 1.

\begin{algorithm}
\caption{FedForget}
\begin{algorithmic}[1]
\REQUIRE Pre-trained global model $\theta_{\text{pretrain}}$, forgetting client ID $f$, hyperparameters $\alpha, \lambda_{\text{neg}}, \lambda_{\text{forget}}$, unlearning rounds $T$
\ENSURE Unlearned model $\theta_{\text{unlearn}}$
\STATE Initialize $\theta_A \leftarrow \theta_{\text{pretrain}}$ (Teacher A)
\STATE Train Teacher B: $\theta_B \leftarrow$ FedAvg on clients $\{1,\ldots,N\}\setminus\{f\}$
\STATE Initialize $\theta^{(0)} \leftarrow \theta_{\text{pretrain}}$
\FOR{$t = 0$ to $T-1$}
    \STATE \textbf{Forgetting client $f$:}
    \STATE \quad Minimize $\mathcal{L}_{\text{total}} = \alpha \mathcal{L}_{\text{pos}}(\theta, \theta_A) - (1-\alpha) \lambda_{\text{neg}} \mathcal{L}_{\text{neg}}(\theta, \theta_B)$
    \STATE \quad Send updated $\theta_f^{(t)}$ to server
    \STATE \textbf{Regular clients:}
    \STATE \quad Standard local training, send $\theta_i^{(t)}$ to server
    \STATE \textbf{Server aggregation:}
    \STATE \quad Compute $w_f^{(t)} = w_f^{(0)} \cdot \exp(-\lambda_{\text{forget}} \cdot t)$
    \STATE \quad $\theta^{(t+1)} = \frac{\sum_{i=1}^{N} w_i^{(t)} \theta_i^{(t)}}{\sum_{i=1}^{N} w_i^{(t)}}$
\ENDFOR
\STATE \textbf{return} $\theta_{\text{unlearn}} = \theta^{(T)}$
\end{algorithmic}
\end{algorithm}

\subsection{Complexity Analysis}

\textbf{Communication Cost}: FedForget requires $O(T)$ rounds of communication, where $T \ll T_{\text{pretrain}}$ (typically $T=10$ vs. $T_{\text{pretrain}}=20-50$). Each round transmits one model per participating client.

\textbf{Computation Cost}: The forgetting client requires $O(T \cdot E \cdot |\mathcal{D}_f|)$ computations for $E$ local epochs. Training Teacher B requires additional $O(T_B \cdot E \cdot \sum_{i \neq f} |\mathcal{D}_i|)$ computations, where $T_B$ is small (typically 3-5 rounds).

\textbf{Storage Cost}: FedForget requires storing two teacher models ($\theta_A$ and $\theta_B$), which is negligible compared to the model size.

Compared to retraining from scratch, FedForget achieves 1.5-2× speedup in our experiments.

\section{Experiments}

\subsection{Experimental Setup}

\subsubsection{Datasets and Models}

We conduct experiments on CIFAR-10 with ResNet-18 architecture. The dataset contains 50,000 training images and 10,000 test images across 10 classes.

\subsubsection{Federated Learning Setup}

We evaluate two configurations:
\begin{itemize}
\item \textbf{5 clients}: Each client has 10,000 training samples
\item \textbf{10 clients}: Each client has 5,000 training samples
\end{itemize}

Data is distributed using Dirichlet allocation with $\alpha=0.5$ to simulate realistic Non-IID scenarios. We select client 0 as the forgetting client in all experiments.

\subsubsection{Training Hyperparameters}

\textbf{Pre-training}: 20 rounds of FedAvg, 2 local epochs per round, learning rate 0.01, batch size 64.

\textbf{FedForget}: 10 unlearning rounds, 2 local epochs per round, learning rate 0.01, $\alpha=0.93$, $\lambda_{\text{neg}}=3.5$, $\lambda_{\text{forget}}=2.0$.

All experiments are repeated for 3 independent runs with different random seeds.

\subsubsection{Baselines}

\begin{itemize}
\item \textbf{Retrain}: Train from scratch excluding client 0's data (gold standard)
\item \textbf{FineTune}: Continue training on remaining clients' data
\end{itemize}

\subsubsection{Evaluation Metrics}

\begin{itemize}
\item \textbf{Retention} = (Test Acc after unlearning / Test Acc before unlearning) × 100\%
\item \textbf{Forgetting Rate} = (1 - Forget Acc after / Forget Acc before) × 100\%
\item \textbf{ASR (Attack Success Rate)}: Membership inference attack success rate via SimpleMIA
\item \textbf{Speedup}: Computation time ratio vs. retraining
\end{itemize}

\subsection{Main Results}

Table 1 shows the main results for 5-client configuration. FedForget achieves the best overall performance:

\begin{itemize}
\item \textbf{Best Privacy}: ASR=52.91±2.32\%, closest to ideal random guessing (50\%)
\item \textbf{Effective Unlearning}: 20.01±1.92\% forgetting rate
\item \textbf{High Utility}: 96.57±1.21\% retention
\item \textbf{Efficient}: 1.53× faster than retraining
\item \textbf{Most Stable}: Lowest coefficient of variation (1.25\%)
\end{itemize}

Notably, FedForget's ASR is significantly better than Retrain (46.74\%) and FineTune (51.14\%), indicating superior privacy protection.

\begin{table}[t]
\centering
\caption{Main Results (5 Clients, CIFAR-10, $\alpha=0.5$)}
\label{tab:main_results}
\begin{tabular}{lcccc}
\toprule
Method & Retention (\%) & Forgetting (\%) & ASR (\%) & Speedup \\
\midrule
Retrain & $93.96 \pm 2.33$ & $\textbf{32.68} \pm \textbf{1.49}$ & $46.74 \pm 2.26$ & 1.00× \\
FineTune & $\textbf{98.22} \pm \textbf{1.79}$ & $15.70 \pm 1.90$ & $51.14 \pm 2.42$ & 2.02× \\
\textbf{FedForget} & $\mathbf{96.57} \pm \mathbf{1.21}$ & $20.01 \pm 1.92$ & $\mathbf{52.91} \pm \mathbf{2.32}$ & $\mathbf{1.53}$× \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Ablation Study}

To validate the contribution of each component, we evaluate four variants shown in Table 2:

\begin{itemize}
\item \textbf{Full FedForget}: Complete method with dual-teacher distillation and dynamic weight adjustment
\item \textbf{Single Teacher}: Only Teacher A (global teacher), no Teacher B
\item \textbf{No Distillation}: No knowledge distillation, only gradient ascent on forgetting data
\item \textbf{No Weight Adjustment}: Dual-teacher distillation without server-side weight decay
\end{itemize}

Key findings:
\begin{itemize}
\item Dual-teacher contributes +11.54\% retention vs. single-teacher, confirming the importance of the clean reference (Teacher B)
\item Without distillation, retention drops to 14.10\%, demonstrating catastrophic forgetting
\item Weight adjustment contributes +4.74\% retention, showing the value of server-side unlearning
\end{itemize}

\begin{table}[t]
\centering
\caption{Ablation Study (5 Clients)}
\label{tab:ablation}
\begin{tabular}{lcc}
\toprule
Variant & Retention (\%) & Impact \\
\midrule
Full FedForget & 101.07 & Baseline \\
Single Teacher & 89.53 & $-11.54$\% \\
No Distillation & 14.10 & $-87.00$\% \\
No Weight Adjustment & 96.33 & $-4.74$\% \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Scalability Analysis}

We compare 5-client vs. 10-client configurations in Table 3. Counter-intuitively, FedForget performs better with more clients:

\begin{itemize}
\item +2.09\% retention improvement (98.66\% vs. 96.57\%)
\item -2.68\% ASR improvement (50.23\% vs. 52.91\%), even closer to ideal 50\%
\item -65\% variance reduction (CV: 0.75\% vs. 2.16\%), indicating higher stability
\end{itemize}

This scalability advantage stems from better data distribution and more robust Teacher B with 9 remaining clients (vs. 4 in 5-client setup).

\begin{table}[t]
\centering
\caption{Scalability: 10 Clients vs. 5 Clients}
\label{tab:scalability}
\begin{tabular}{lccc}
\toprule
Metric & 5 Clients & 10 Clients & Improvement \\
\midrule
Retention (\%) & $96.57 \pm 1.21$ & $\mathbf{98.66} \pm \mathbf{0.74}$ & $+2.09$\% \\
ASR (\%) & $52.91 \pm 2.32$ & $\mathbf{50.23} \pm \mathbf{1.90}$ & $-2.68$\% \\
CV (\%) & 2.16 & \textbf{0.75} & $-65$\% \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Privacy Evaluation}

We employ SimpleMIA to evaluate privacy protection. SimpleMIA trains an attack classifier using loss values to distinguish members (training data) from non-members (test data).

Results show FedForget achieves ASR=52.91\% (5 clients) and 50.23\% (10 clients), both very close to random guessing (50\%). This is significantly better than Retrain (46.74\%) and competitive with FineTune (51.14\%).

The near-ideal ASR indicates that forgetting data is indistinguishable from test data, providing strong privacy guarantees.

\subsection{Non-IID Robustness}

We evaluate FedForget's robustness across different Non-IID levels using Dirichlet $\alpha \in \{0.1, 0.3, 0.5, 0.7, 1.0\}$. Results show FedForget maintains stable performance across all settings:

\begin{itemize}
\item Extreme Non-IID ($\alpha=0.1$): Retention=96.02\%, demonstrating robustness even when data is highly skewed
\item Near-IID ($\alpha=1.0$): Retention=95.83\%, showing effectiveness in balanced settings
\item Optimal at $\alpha=0.5$: Retention=96.57\%, ASR=52.91\%
\end{itemize}

This validates FedForget's applicability to diverse real-world federated scenarios.

\section{Discussion}

\subsection{Why Dual-Teacher Works}

The success of dual-teacher distillation stems from complementary roles: Teacher A prevents catastrophic forgetting by preserving the overall feature space, while Teacher B guides precise unlearning by providing a clean reference. This addresses the fundamental limitation of single-teacher approaches where the teacher contains forgetting client's knowledge.

\subsection{Scalability Insights}

The counter-intuitive scalability result (10 clients better than 5 clients) has important implications. With more remaining clients, Teacher B becomes more robust and representative, leading to better guidance for unlearning. This suggests FedForget is particularly suitable for large-scale federated systems.

\subsection{Privacy-Utility Trade-off}

FedForget achieves the best privacy-utility balance: ASR closest to 50\% (privacy) while maintaining 96.57\% retention (utility). This is achieved through careful tuning of $\alpha$ and $\lambda_{\text{neg}}$, which control the preservation-forgetting trade-off.

\subsection{Computational Efficiency}

FedForget requires training Teacher B (3-5 rounds) and unlearning rounds (10 rounds), totaling ~15 rounds vs. ~20 rounds for retraining. The 1.53× speedup comes from faster convergence due to warm-starting from the pre-trained model.

\subsection{Limitations}

\textbf{Teacher B Training Cost}: Training Teacher B requires participation from all remaining clients, which may not always be feasible. Future work could explore approximating Teacher B using a subset of clients or synthetic data.

\textbf{Hyperparameter Sensitivity}: FedForget requires tuning $\alpha$, $\lambda_{\text{neg}}$, and $\lambda_{\text{forget}}$. While we provide recommended values ($\alpha=0.93$, $\lambda_{\text{neg}}=3.5$, $\lambda_{\text{forget}}=2.0$), optimal values may vary across datasets and FL settings.

\textbf{Multiple Forgetting Clients}: Our current evaluation focuses on single-client unlearning. Extending to multiple simultaneous forgetting requests requires further investigation.

\subsection{Future Directions}

\textbf{Theoretical Guarantees}: While our empirical results are strong, developing formal unlearning guarantees for FedForget is an important direction.

\textbf{Adaptive Hyperparameters}: Automatically adapting $\alpha$ and $\lambda_{\text{neg}}$ based on unlearning progress could improve robustness.

\textbf{Cross-Device Federated Learning}: Evaluating FedForget in cross-device settings with thousands of clients and extreme heterogeneity.

\section{Conclusion}

We presented FedForget, a novel federated unlearning method combining dual-teacher knowledge distillation with server-side dynamic weight adjustment. Extensive experiments on CIFAR-10 demonstrate that FedForget achieves superior multi-dimensional performance: 96.57\% retention, 20.01\% forgetting rate, ASR=52.91\% (closest to ideal 50\%), and 1.53× speedup. Our ablation study confirms that dual-teacher distillation contributes +11.54\% retention over single-teacher approaches. Notably, FedForget exhibits counter-intuitive scalability, with 10-client configuration outperforming 5-client by +2.09\% retention. This work provides the first comprehensive evaluation of federated unlearning aligned with NeurIPS 2024 standards, offering a practical solution for privacy-preserving federated learning. Future work includes developing theoretical guarantees, adaptive hyperparameters, and evaluation in cross-device settings.

\bibliographystyle{plain}
\bibliography{references}

\end{document}
