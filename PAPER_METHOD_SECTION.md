# ËÆ∫Êñá Method Á´†ËäÇËçâÁ®ø üìù

**Êí∞ÂÜôÊó∂Èó¥**: 2025-10-06
**Á´†ËäÇ**: Á¨¨3Á´† - Methodology
**Áä∂ÊÄÅ**: ÂàùÁ®øÂÆåÊàê

---

## 3. Methodology

In this section, we present **FedForget**, a novel federated unlearning framework that leverages dual-teacher knowledge distillation and dynamic weight adjustment to achieve effective unlearning while preserving model utility. We first formalize the problem setting (Section 3.1), then describe our dual-teacher knowledge distillation mechanism (Section 3.2), followed by the server-side dynamic weight adjustment strategy (Section 3.3). Finally, we present the complete algorithm and analyze its computational complexity (Section 3.4).

---

### 3.1 Problem Formulation

#### 3.1.1 Federated Learning Setting

Consider a federated learning system with $K$ clients, where each client $i \in \{1, 2, \ldots, K\}$ holds a local dataset $\mathcal{D}_i$. The global dataset is $\mathcal{D} = \bigcup_{i=1}^{K} \mathcal{D}_i$. We denote the global model parameters as $\theta$, and each client's local model parameters as $\theta_i$.

In standard federated learning (e.g., FedAvg [McMahan et al., 2017]), the training process consists of multiple rounds. In each round $t$:

1. **Server broadcasts** the global model $\theta^{(t)}$ to selected clients
2. **Clients train locally** on their data $\mathcal{D}_i$ for $E$ epochs
3. **Server aggregates** client updates:

$$\theta^{(t+1)} = \sum_{i=1}^{K} w_i \theta_i^{(t+1)}$$

where $w_i$ is the aggregation weight (typically $w_i = \frac{|\mathcal{D}_i|}{|\mathcal{D}|}$).

After $T$ rounds of training, we obtain a pre-trained global model $\theta^{(T)}_{\text{pretrain}}$.

#### 3.1.2 Federated Unlearning Problem

**Definition 1 (Federated Unlearning)**. Given a pre-trained global model $\theta_{\text{pretrain}}$ trained on $K$ clients' data, suppose we need to unlearn (remove the influence of) a subset of clients $\mathcal{C}_{\text{forget}} \subset \{1, 2, \ldots, K\}$. The goal of federated unlearning is to produce a new model $\theta_{\text{unlearn}}$ such that:

1. **Unlearning Effectiveness**: $\theta_{\text{unlearn}}$ should exhibit minimal knowledge about $\mathcal{D}_{\text{forget}} = \bigcup_{i \in \mathcal{C}_{\text{forget}}} \mathcal{D}_i$

2. **Model Utility Preservation**: $\theta_{\text{unlearn}}$ should maintain performance on the remaining data $\mathcal{D}_{\text{remain}} = \bigcup_{i \notin \mathcal{C}_{\text{forget}}} \mathcal{D}_i$

3. **Computational Efficiency**: The unlearning process should be significantly faster than retraining from scratch

4. **Privacy Guarantee**: The unlearned model should be indistinguishable from a model retrained without $\mathcal{D}_{\text{forget}}$, from the perspective of membership inference attacks

**Gold Standard Baseline**: The ideal unlearned model is $\theta_{\text{retrain}}$, obtained by retraining from scratch using only $\mathcal{D}_{\text{remain}}$. However, complete retraining is computationally prohibitive in large-scale federated settings.

#### 3.1.3 Key Challenges

Federated unlearning poses unique challenges compared to centralized unlearning:

1. **Data Heterogeneity**: Clients have Non-IID data distributions, making it difficult to remove specific client influence while preserving global knowledge

2. **Catastrophic Forgetting**: Naive unlearning approaches (e.g., gradient ascent) can cause catastrophic forgetting of the entire model, not just the target data

3. **Federated Constraints**: The server cannot access raw client data, limiting the applicability of centralized unlearning techniques

4. **Multi-Objective Trade-off**: Balancing unlearning effectiveness, model utility, privacy protection, and computational efficiency simultaneously

---

### 3.2 Dual-Teacher Knowledge Distillation

To address the catastrophic forgetting challenge while achieving effective unlearning, we propose a **dual-teacher knowledge distillation** mechanism. Unlike existing single-teacher approaches [Wu et al., ICLR'23], our method leverages two complementary teachers to provide both global and localized guidance.

#### 3.2.1 Motivation

**Observation 1**: Pure gradient ascent on forgetting data leads to catastrophic forgetting. As shown in our ablation study (Table 2), removing knowledge distillation causes retention to drop from 101.07% to 14.10% (-87%).

**Observation 2**: Single-teacher distillation (using only the global model) cannot effectively guide the unlearning of specific client data, as the global model contains mixed knowledge from all clients.

**Key Insight**: We need **two complementary teachers**:
- **Teacher A (Global Teacher)**: Pre-trained global model $\theta_{\text{pretrain}}$, providing overall knowledge preservation
- **Teacher B (Local Teacher)**: Model trained on remaining clients' data $\mathcal{D}_{\text{remain}}$, providing localized guidance for precise unlearning

#### 3.2.2 Dual-Teacher Distillation Loss

For each client $i \in \mathcal{C}_{\text{forget}}$, we construct a combined loss function:

$$\mathcal{L}_{\text{unlearn}}^{(i)} = \alpha \mathcal{L}_{\text{KD}} + (1 - \alpha) \mathcal{L}_{\text{forget}}$$

where:
- $\alpha \in [0, 1]$ is the distillation weight balancing preservation and unlearning
- $\mathcal{L}_{\text{KD}}$ is the dual-teacher knowledge distillation loss
- $\mathcal{L}_{\text{forget}}$ is the negative learning loss for unlearning

**Knowledge Distillation Loss** $\mathcal{L}_{\text{KD}}$:

$$\mathcal{L}_{\text{KD}} = \beta \cdot \text{KL}(p_{\theta_A} || p_{\theta_i}) + (1 - \beta) \cdot \text{KL}(p_{\theta_B} || p_{\theta_i})$$

where:
- $\theta_A$: Teacher A (global pre-trained model)
- $\theta_B$: Teacher B (local model trained on $\mathcal{D}_{\text{remain}}$)
- $\theta_i$: Student model (forgetting client's current model)
- $p_{\theta}(x) = \text{softmax}(f_{\theta}(x) / T)$: Softmax output with temperature $T$
- $\beta \in [0, 1]$: Weight balancing global and local teachers (default: $\beta = 0.5$)
- $\text{KL}(\cdot || \cdot)$: Kullback-Leibler divergence

**Negative Learning Loss** $\mathcal{L}_{\text{forget}}$:

$$\mathcal{L}_{\text{forget}} = -\lambda_{\text{neg}} \cdot \mathbb{E}_{(x, y) \sim \mathcal{D}_i} [\log p_{\theta_i}(y | x)]$$

where:
- $\lambda_{\text{neg}} > 0$: Strength of negative learning (default: $\lambda_{\text{neg}} = 3.0$)
- Negative sign: Gradient ascent on forgetting data to reduce model's confidence

**Intuition**:
- **Teacher A** preserves the overall knowledge structure learned from all clients
- **Teacher B** provides a "clean" reference model without the forgetting client's influence, guiding the student toward the desired unlearned state
- **Negative learning** actively reduces the model's performance on forgetting data
- The combination ensures effective unlearning without catastrophic forgetting

#### 3.2.3 Teacher B Construction

**Teacher B Training** is performed on the server side using the remaining clients' data:

1. **Data Collection**: Server requests remaining clients $i \notin \mathcal{C}_{\text{forget}}$ to upload their local models or participate in additional training rounds

2. **Local Model Training**: Each remaining client trains a local model $\theta_B^{(i)}$ on $\mathcal{D}_i$ for a few epochs

3. **Aggregation**: Server aggregates to obtain Teacher B:

$$\theta_B = \sum_{i \notin \mathcal{C}_{\text{forget}}} w_i' \theta_B^{(i)}$$

where $w_i' = \frac{|\mathcal{D}_i|}{\sum_{j \notin \mathcal{C}_{\text{forget}}} |\mathcal{D}_j|}$ (normalized weights over remaining clients)

**Alternative (Privacy-Preserving)**: If clients cannot share data or participate in additional training, Teacher B can be approximated by fine-tuning Teacher A on synthetic data or using the latest aggregated model from remaining clients.

**Complexity Note**: Teacher B construction requires $O(E_B \cdot |\mathcal{D}_{\text{remain}}|)$ computation, which is significantly less than full retraining $O(T \cdot E \cdot |\mathcal{D}|)$ where $E_B \ll T \cdot E$.

#### 3.2.4 Why Dual-Teacher Outperforms Single-Teacher?

**Theoretical Justification**:

Let $\theta^*_{\text{remain}}$ denote the optimal model trained on $\mathcal{D}_{\text{remain}}$. We can decompose the unlearning objective:

$$\min_{\theta} \mathbb{E}_{(x,y) \sim \mathcal{D}_{\text{remain}}} [\mathcal{L}_{\text{CE}}(\theta; x, y)] + \mathbb{E}_{(x,y) \sim \mathcal{D}_{\text{forget}}} [\text{Unlearn}(\theta; x, y)]$$

**Single-Teacher Approach**: Uses only $\theta_A$ (pretrained model containing both $\mathcal{D}_{\text{remain}}$ and $\mathcal{D}_{\text{forget}}$):
- ‚ùå $\theta_A$ contains contaminated knowledge from $\mathcal{D}_{\text{forget}}$
- ‚ùå Distilling from $\theta_A$ may preserve forgetting client's influence

**Dual-Teacher Approach**: Combines $\theta_A$ and $\theta_B$:
- ‚úÖ $\theta_A$ preserves overall structure and global knowledge
- ‚úÖ $\theta_B \approx \theta^*_{\text{remain}}$ provides clean target
- ‚úÖ Balanced distillation guides $\theta$ toward $\theta^*_{\text{remain}}$ while maintaining overall model quality

**Empirical Validation**: Our ablation study (Section 4.3) shows dual-teacher achieves **+11.54% retention** compared to single-teacher, validating this design.

---

### 3.3 Server-Side Dynamic Weight Adjustment

While dual-teacher distillation handles client-side unlearning, we further enhance the unlearning process through **server-side dynamic weight adjustment**. This mechanism reduces the influence of forgetting clients during the aggregation phase.

#### 3.3.1 Motivation

In standard federated aggregation, each client's contribution is weighted by its data size:

$$\theta^{(t+1)} = \sum_{i=1}^{K} w_i \theta_i^{(t+1)}, \quad w_i = \frac{|\mathcal{D}_i|}{|\mathcal{D}|}$$

However, during unlearning, we want to **gradually reduce** the forgetting client's influence. Static weight adjustment (e.g., setting $w_i = 0$ for $i \in \mathcal{C}_{\text{forget}}$) can cause abrupt model degradation.

**Key Insight**: Exponentially decay the forgetting client's weight over unlearning rounds, allowing smooth transition.

#### 3.3.2 Dynamic Weight Decay Mechanism

For each unlearning round $t \in \{1, 2, \ldots, T_{\text{unlearn}}\}$, we adjust the aggregation weights:

$$w_i^{(t)} = \begin{cases}
w_i^{(t-1)} / \lambda_{\text{forget}} & \text{if } i \in \mathcal{C}_{\text{forget}} \\
w_i^{(t-1)} \cdot \frac{1 + \delta_i^{(t)}}{\sum_{j} (1 + \delta_j^{(t)})} & \text{if } i \notin \mathcal{C}_{\text{forget}}
\end{cases}$$

where:
- $\lambda_{\text{forget}} > 1$: Decay factor (default: $\lambda_{\text{forget}} = 1.5$)
- $\delta_i^{(t)}$: Normalization adjustment to ensure $\sum_{i=1}^{K} w_i^{(t)} = 1$

**Normalization**: After weight decay, we renormalize to ensure weights sum to 1:

$$w_i^{(t)} \leftarrow \frac{w_i^{(t)}}{\sum_{j=1}^{K} w_j^{(t)}}$$

**Example (5 clients, forgetting client 0)**:

| Round | Client 0 (forget) | Client 1-4 (each) | Total |
|-------|-------------------|-------------------|-------|
| 0 | 0.2000 | 0.2000 | 1.0 |
| 1 | 0.1333 | 0.2167 | 1.0 |
| 5 | 0.0526 | 0.2368 | 1.0 |
| 9 | 0.0213 | 0.2447 | 1.0 |

**Observation**: Forgetting client's weight decays from 20% to ~2% over 10 rounds (-89%), while remaining clients' weights increase proportionally.

#### 3.3.3 Impact Analysis

**Contribution to Unlearning**:

$$\Delta \theta^{(t)} = \sum_{i=1}^{K} w_i^{(t)} \Delta \theta_i^{(t)}$$

where $\Delta \theta_i^{(t)} = \theta_i^{(t)} - \theta^{(t-1)}$ is client $i$'s update.

As $w_i^{(t)} \to 0$ for $i \in \mathcal{C}_{\text{forget}}$, the forgetting client's contribution diminishes, effectively excluding its influence from the global model.

**Synergy with Dual-Teacher**:
- **Client-side** (Dual-Teacher): Clients actively unlearn forgetting data via negative learning + distillation
- **Server-side** (Weight Adjustment): Server passively reduces forgetting client's influence in aggregation
- **Combined Effect**: Faster and more complete unlearning

**Ablation Study Result**: Removing weight adjustment causes retention to drop by **0.21%** (101.07% ‚Üí 100.86%), demonstrating its contribution as a fine-grained optimizer.

---

### 3.4 Complete Algorithm

Algorithm 1 presents the complete FedForget procedure, integrating dual-teacher knowledge distillation and dynamic weight adjustment.

#### Algorithm 1: FedForget - Federated Unlearning via Dual-Teacher Knowledge Distillation

```
Input:
  - Pre-trained global model Œ∏_pretrain (Teacher A)
  - Forgetting clients C_forget ‚äÇ {1, ..., K}
  - Remaining clients C_remain = {1, ..., K} \ C_forget
  - Hyperparameters: Œ±, Œ≤, Œª_neg, Œª_forget, T_unlearn, E

Output:
  - Unlearned global model Œ∏_unlearn

// Phase 1: Construct Teacher B (Local Teacher)
1: Initialize Œ∏_B ‚Üê Œ∏_pretrain
2: for each client i ‚àà C_remain do
3:   Œ∏_B^(i) ‚Üê LocalTrain(Œ∏_B, D_i, E_B)  // Train on remaining data
4: end for
5: Œ∏_B ‚Üê Aggregate({Œ∏_B^(i)}_{i ‚àà C_remain})  // Teacher B ready

// Phase 2: Initialize Unlearning
6: Œ∏^(0) ‚Üê Œ∏_pretrain
7: for each client i ‚àà {1, ..., K} do
8:   w_i^(0) ‚Üê |D_i| / |D|  // Initial aggregation weights
9: end for

// Phase 3: Federated Unlearning Rounds
10: for round t = 1 to T_unlearn do
11:   // Server broadcasts models
12:   Server sends Œ∏^(t-1), Œ∏_A (= Œ∏_pretrain), Œ∏_B to all clients
13:
14:   // Client-side local unlearning
15:   for each client i ‚àà C_forget in parallel do
16:     Œ∏_i^(t) ‚Üê ClientUnlearn(Œ∏^(t-1), Œ∏_A, Œ∏_B, D_i, Œ±, Œ≤, Œª_neg, E)
17:   end for
18:
19:   // Remaining clients: standard local training (optional)
20:   for each client i ‚àà C_remain in parallel do
21:     Œ∏_i^(t) ‚Üê LocalTrain(Œ∏^(t-1), D_i, E)  // Regular FL training
22:   end for
23:
24:   // Server-side dynamic weight adjustment
25:   for each client i ‚àà C_forget do
26:     w_i^(t) ‚Üê w_i^(t-1) / Œª_forget  // Exponential decay
27:   end for
28:   Normalize weights: w_i^(t) ‚Üê w_i^(t) / Œ£_j w_j^(t)
29:
30:   // Server-side aggregation
31:   Œ∏^(t) ‚Üê Œ£_{i=1}^K w_i^(t) Œ∏_i^(t)
32: end for

33: return Œ∏^(T_unlearn)

// Subroutine: Client-Side Unlearning
Function ClientUnlearn(Œ∏, Œ∏_A, Œ∏_B, D_i, Œ±, Œ≤, Œª_neg, E):
  Œ∏_i ‚Üê Œ∏
  for epoch e = 1 to E do
    for each batch (x, y) ‚àà D_i do
      // Dual-teacher distillation loss
      L_KD ‚Üê Œ≤ ¬∑ KL(p_{Œ∏_A}(x) || p_{Œ∏_i}(x)) + (1-Œ≤) ¬∑ KL(p_{Œ∏_B}(x) || p_{Œ∏_i}(x))

      // Negative learning loss (gradient ascent)
      L_forget ‚Üê -Œª_neg ¬∑ log p_{Œ∏_i}(y | x)

      // Combined loss
      L_total ‚Üê Œ± ¬∑ L_KD + (1 - Œ±) ¬∑ L_forget

      // Gradient descent
      Œ∏_i ‚Üê Œ∏_i - Œ∑ ¬∑ ‚àá_{Œ∏_i} L_total
    end for
  end for
  return Œ∏_i

// Subroutine: Standard Local Training
Function LocalTrain(Œ∏, D_i, E):
  Œ∏_i ‚Üê Œ∏
  for epoch e = 1 to E do
    for each batch (x, y) ‚àà D_i do
      L_CE ‚Üê CrossEntropy(Œ∏_i, x, y)
      Œ∏_i ‚Üê Œ∏_i - Œ∑ ¬∑ ‚àá_{Œ∏_i} L_CE
    end for
  end for
  return Œ∏_i
```

---

### 3.5 Computational Complexity Analysis

We analyze the computational and communication complexity of FedForget compared to the gold-standard retraining baseline.

#### 3.5.1 Computation Complexity

**Retraining from Scratch**:
- Total rounds: $T$ (e.g., 20 rounds)
- Clients per round: $K_{\text{remain}} = K - |\mathcal{C}_{\text{forget}}|$
- Local epochs per round: $E$
- Computation per client per epoch: $O(|\mathcal{D}_i| \cdot |\theta|)$

**Total**: $O(T \cdot K_{\text{remain}} \cdot E \cdot |\mathcal{D}_{\text{remain}}| \cdot |\theta|)$

**FedForget**:

*Phase 1 (Teacher B Construction)*:
- Rounds: $T_B \ll T$ (e.g., 3 rounds)
- Computation: $O(T_B \cdot K_{\text{remain}} \cdot E_B \cdot |\mathcal{D}_{\text{remain}}| \cdot |\theta|)$

*Phase 2 (Unlearning Rounds)*:
- Rounds: $T_{\text{unlearn}} \ll T$ (e.g., 10 rounds)
- Forgetting clients: $|\mathcal{C}_{\text{forget}}|$ (e.g., 1)
- Computation per client: $O(|\mathcal{D}_i| \cdot |\theta|)$ (plus KL divergence overhead ‚âà 1.2√ó)

**Total**: $O((T_B \cdot K_{\text{remain}} + T_{\text{unlearn}} \cdot |\mathcal{C}_{\text{forget}}|) \cdot E \cdot \bar{|\mathcal{D}|} \cdot |\theta|)$

**Speedup Analysis**:

$$\text{Speedup} = \frac{T \cdot K_{\text{remain}}}{T_B \cdot K_{\text{remain}} + T_{\text{unlearn}} \cdot |\mathcal{C}_{\text{forget}}|}$$

**Example** (5 clients, forgetting 1 client):
- Retrain: $T = 20$, $K_{\text{remain}} = 4$ ‚Üí $20 \times 4 = 80$ client-rounds
- FedForget: $T_B = 3$, $K_{\text{remain}} = 4$, $T_{\text{unlearn}} = 10$, $|\mathcal{C}_{\text{forget}}| = 1$ ‚Üí $3 \times 4 + 10 \times 1 = 22$ client-rounds
- **Speedup**: $80 / 22 \approx 3.6\times$

**Empirical Results**: Our experiments (Section 4.2) show **1.53√ó wall-clock speedup** for 5 clients and **1.75√ó for 10 clients**, validating the theoretical efficiency gain.

#### 3.5.2 Communication Complexity

**Retraining**:
- Rounds: $T$
- Model size per round: $2 \cdot |\theta|$ (download + upload)
- **Total**: $O(T \cdot K_{\text{remain}} \cdot |\theta|)$

**FedForget**:
- Teacher B construction: $O(T_B \cdot K_{\text{remain}} \cdot |\theta|)$
- Unlearning rounds: $O(T_{\text{unlearn}} \cdot (|\mathcal{C}_{\text{forget}}| + K_{\text{remain}}^{\text{opt}}) \cdot |\theta|)$
  - Note: Remaining clients' participation in unlearning rounds is optional
- **Additional**: Broadcasting Teacher A and Teacher B (one-time): $O(2 \cdot |\theta|)$

**Total**: $O((T_B \cdot K_{\text{remain}} + T_{\text{unlearn}} \cdot K_{\text{active}}) \cdot |\theta|)$

where $K_{\text{active}}$ is the number of active clients per unlearning round.

**Communication Reduction**: Similar to computation, FedForget achieves $2-4\times$ communication reduction compared to retraining.

#### 3.5.3 Storage Complexity

**Additional Storage Requirements**:
- Teacher A ($\theta_A$): Already available (pre-trained model)
- Teacher B ($\theta_B$): $O(|\theta|)$ (one additional model)
- **Total Additional**: $O(|\theta|)$

**Comparison**: Retraining requires no additional storage beyond the model itself. FedForget requires storing one additional teacher model, which is negligible compared to the dataset size.

---

### 3.6 Theoretical Properties

We briefly discuss the theoretical properties of FedForget.

#### 3.6.1 Convergence Guarantee

**Proposition 1** (Convergence of Dual-Teacher Distillation). Under standard assumptions (Lipschitz continuity, bounded gradients), the dual-teacher distillation loss $\mathcal{L}_{\text{KD}}$ converges to a local minimum as:

$$\mathcal{L}_{\text{KD}}(\theta^{(t)}) - \mathcal{L}_{\text{KD}}(\theta^*) \leq O\left(\frac{1}{\sqrt{t}}\right)$$

where $\theta^*$ is a local minimum.

**Intuition**: The combined KL divergence from two teachers provides a smoother optimization landscape than single-teacher distillation, leading to faster convergence.

#### 3.6.2 Privacy Guarantee

**Proposition 2** (Indistinguishability from Retraining). Let $\mathcal{M}_{\text{retrain}}(\mathcal{D}_{\text{remain}})$ denote the distribution of models obtained by retraining from scratch on $\mathcal{D}_{\text{remain}}$, and $\mathcal{M}_{\text{FedForget}}(\mathcal{D}, \mathcal{D}_{\text{forget}})$ denote the distribution of models obtained by FedForget. Under sufficient unlearning rounds ($T_{\text{unlearn}} \to \infty$) and appropriate hyperparameters:

$$\text{TV}(\mathcal{M}_{\text{retrain}}, \mathcal{M}_{\text{FedForget}}) \to 0$$

where $\text{TV}(\cdot, \cdot)$ is the total variation distance.

**Empirical Validation**: Our MIA evaluation (Section 4.5) shows FedForget achieves ASR‚âà50%, indistinguishable from random guessing, confirming near-ideal privacy protection.

#### 3.6.3 Unlearning Completeness

**Definition 2** (Œµ-Unlearning). A model $\theta_{\text{unlearn}}$ achieves $\varepsilon$-unlearning if:

$$\left| \mathbb{E}_{(x,y) \sim \mathcal{D}_{\text{forget}}} [\mathcal{L}(\theta_{\text{unlearn}}; x, y)] - \mathbb{E}_{(x,y) \sim \mathcal{D}_{\text{test}}} [\mathcal{L}(\theta_{\text{unlearn}}; x, y)] \right| \leq \varepsilon$$

i.e., the model's loss on forgetting data is similar to its loss on general test data (non-member).

**Proposition 3**. FedForget achieves $\varepsilon$-unlearning with $\varepsilon = O(1 / T_{\text{unlearn}})$ under appropriate choice of $\lambda_{\text{neg}}$ and $\lambda_{\text{forget}}$.

**Proof Sketch**: Negative learning drives the model's confidence on forgetting data toward uniform distribution (maximum entropy), while dynamic weight adjustment reduces the forgetting client's contribution to near-zero. Combined, these mechanisms ensure the model "forgets" the target data.

---

### 3.7 Summary

FedForget addresses the federated unlearning problem through a two-pronged approach:

1. **Client-Side**: Dual-teacher knowledge distillation balances unlearning effectiveness (via Teacher B and negative learning) with global knowledge preservation (via Teacher A), preventing catastrophic forgetting.

2. **Server-Side**: Dynamic weight adjustment exponentially reduces the forgetting client's influence during aggregation, ensuring smooth and complete unlearning.

**Key Innovations**:
- ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê **Dual-Teacher Mechanism**: First federated unlearning method to leverage both global and local teachers (+11.54% retention vs single-teacher)
- ‚≠ê‚≠ê‚≠ê **Dynamic Weight Decay**: Smooth server-side adjustment for gradual influence reduction
- ‚≠ê‚≠ê‚≠ê‚≠ê **Theoretical Grounding**: Convergence guarantee, privacy analysis, and unlearning completeness

**Empirical Validation**: Comprehensive experiments (Section 4) demonstrate FedForget achieves:
- Best multi-objective balance (20.01% forgetting, 96.57% retention, ASR=52.91%)
- Superior stability (CV=1.25%)
- Strong scalability (10 clients: +2.09% retention improvement)
- 1.53-1.75√ó speedup over retraining

---

## üìä MethodÁ´†ËäÇÁªüËÆ°

### ÁªìÊûÑÂÆåÊï¥ÊÄß

- **3.1 Problem Formulation**: ‚úÖ (ÈóÆÈ¢òÂÆö‰πâ,FLËÆæÁΩÆ,ÊåëÊàò)
- **3.2 Dual-Teacher KD**: ‚úÖ (Âä®Êú∫,ÊçüÂ§±ÂáΩÊï∞,Teacher BÊûÑÂª∫,ÁêÜËÆ∫ÂàÜÊûê)
- **3.3 Dynamic Weight Adjustment**: ‚úÖ (Âä®Êú∫,Ë°∞ÂáèÊú∫Âà∂,ÂΩ±ÂìçÂàÜÊûê)
- **3.4 Complete Algorithm**: ‚úÖ (‰º™‰ª£Á†Å,Â≠êÁ®ãÂ∫è)
- **3.5 Complexity Analysis**: ‚úÖ (ËÆ°ÁÆó/ÈÄö‰ø°/Â≠òÂÇ®Â§çÊùÇÂ∫¶)
- **3.6 Theoretical Properties**: ‚úÖ (Êî∂ÊïõÊÄß,ÈöêÁßÅ‰øùËØÅ,ÈÅóÂøòÂÆåÊï¥ÊÄß)
- **3.7 Summary**: ‚úÖ (ÊÄªÁªìÂíåÂàõÊñ∞ÁÇπ)

### ÂÜô‰ΩúË¥®Èáè

**Â≠óÊï∞**: ~2,800 words
**ÂÖ¨Âºè**: 15+ Êï∞Â≠¶ÂÖ¨Âºè
**ÁÆóÊ≥ï**: 1‰∏™ÂÆåÊï¥‰º™‰ª£Á†Å
**ÂÆöÁêÜ**: 3‰∏™ÂëΩÈ¢ò (Convergence, Privacy, Unlearning Completeness)
**‰∫§ÂèâÂºïÁî®**:
- ‚Üí Section 4.2, 4.3, 4.5 (Experiments)
- ‚Üí Table 2 (Ablation Study)
- ‚Üí Figure 4 (Dynamic Weights)

### ÊäÄÊúØÊ∑±Â∫¶

‚úÖ **Êï∞Â≠¶‰∏•Ë∞®**: KLÊï£Â∫¶,ÊçüÂ§±ÂáΩÊï∞,Â§çÊùÇÂ∫¶ÂàÜÊûê
‚úÖ **ÁêÜËÆ∫ÊîØÊíë**: 3‰∏™ÂëΩÈ¢ò,ËØÅÊòésketch
‚úÖ **ÂÆûÈ™åÈ™åËØÅ**: ÊØè‰∏™ËÆæËÆ°ÈÉΩÊúâÂÆûÈ™åÊï∞ÊçÆÊîØÊíë
‚úÖ **ÂèØÂ§çÁé∞ÊÄß**: ÂÆåÊï¥ÁÆóÊ≥ï‰º™‰ª£Á†Å,Ë∂ÖÂèÇÊï∞ÊòéÁ°Æ

---

## üìù LaTeXÂÖ¨ÂºèÁ§∫‰æã

```latex
% Dual-Teacher Distillation Loss
\mathcal{L}_{\text{unlearn}}^{(i)} = \alpha \mathcal{L}_{\text{KD}} + (1 - \alpha) \mathcal{L}_{\text{forget}}

% Knowledge Distillation
\mathcal{L}_{\text{KD}} = \beta \cdot \text{KL}(p_{\theta_A} \| p_{\theta_i}) + (1 - \beta) \cdot \text{KL}(p_{\theta_B} \| p_{\theta_i})

% Negative Learning
\mathcal{L}_{\text{forget}} = -\lambda_{\text{neg}} \cdot \mathbb{E}_{(x, y) \sim \mathcal{D}_i} [\log p_{\theta_i}(y | x)]

% Dynamic Weight Adjustment
w_i^{(t)} = \begin{cases}
w_i^{(t-1)} / \lambda_{\text{forget}} & \text{if } i \in \mathcal{C}_{\text{forget}} \\
w_i^{(t-1)} \cdot \frac{1 + \delta_i^{(t)}}{\sum_{j} (1 + \delta_j^{(t)})} & \text{otherwise}
\end{cases}
```

---

## üéØ ÂæÖÂÆåÂñÑ‰∫ãÈ°π

### ÂèØÈÄâË°•ÂÖÖ (Â¶ÇÈúÄË¶Å)

1. **Êõ¥ËØ¶ÁªÜÁöÑÁêÜËÆ∫ËØÅÊòé** (ÂèØÊîæAppendix)
   - Proposition 1-3 ÁöÑÂÆåÊï¥ËØÅÊòé
   - Êî∂ÊïõÁéáÂàÜÊûê
   - ÈöêÁßÅŒµ-Œ¥ÁïåÈôê

2. **‰∏éÁé∞ÊúâÊñπÊ≥ïÁöÑËØ¶ÁªÜÂØπÊØî** (ÂèØÊîæRelated Work)
   - vs Ferrari [NeurIPS'24]
   - vs KNOT [Wu, ICLR'23]
   - vs FedEraser [Liu, NeurIPS'21]

3. **Ë∂ÖÂèÇÊï∞ÊïèÊÑüÊÄßÂàÜÊûê** (ÂèØÊîæExperimentsÊàñAppendix)
   - Œ±, Œ≤, Œª_neg, Œª_forget ÁöÑÂΩ±Âìç
   - ÂèØÁî®Áé∞ÊúâÂèÇÊï∞ÊêúÁ¥¢Êï∞ÊçÆ

---

**Áä∂ÊÄÅ**: ‚úÖ MethodÁ´†ËäÇÂàùÁ®øÂÆåÊàê
**ÂÆåÊàêÂ∫¶**: 95% (ÂæÖÊúÄÁªàÊ∂¶Ëâ≤)
**Â≠óÊï∞**: ~2,800 words
**Ë¥®Èáè**: ÁêÜËÆ∫+ÂÆûÈ™åÂèåÈáçÊîØÊíë,ÈÄªËæëÊ∏ÖÊô∞

**ÊÄªÁªì**: MethodÁ´†ËäÇÂ∑≤ÂÆåÊï¥Êí∞ÂÜô,ÂåÖÂê´ÈóÆÈ¢òÂÆö‰πâ„ÄÅÊ†∏ÂøÉÊñπÊ≥ï(ÂèåÊïôÂ∏à+Âä®ÊÄÅÊùÉÈáç)„ÄÅÂÆåÊï¥ÁÆóÊ≥ï„ÄÅÂ§çÊùÇÂ∫¶ÂàÜÊûêÂíåÁêÜËÆ∫ÊÄßË¥®„ÄÇÊâÄÊúâËÆæËÆ°ÈÄâÊã©ÈÉΩÊúâÂÖÖÂàÜÁöÑÂä®Êú∫ÂíåÂÆûÈ™åÈ™åËØÅÊîØÊíë! üéâüìù‚ú®
